{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KlsWlLqiWih"
      },
      "source": [
        "# Experiment II : Recurrent Neural Networks\n",
        "\n",
        "**Author:** Felipe Cortes Jaramillo\n",
        "\n",
        "**Description:** Experiments implementing different recurrent neural network\n",
        "\n",
        "**References:** https://github.com/tommytracey/AIND-Capstone/blob/master/machine_translation.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO5vkfQLo4ZD"
      },
      "source": [
        "## Installing Packages and Downloading Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY0tW5-RfibX",
        "outputId": "355c76c2-85b3-41da-a5f5-b40c402dfe63"
      },
      "outputs": [],
      "source": [
        "# Install Hugging Face Library for Datasets\n",
        "#!pip install datasets pandas nltk clean-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Yi1ZQkSgSF5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pacho\\miniconda3\\envs\\tf-dl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ],
      "source": [
        "# Import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "\n",
        "import nltk\n",
        "from cleantext import clean\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, SimpleRNN, Dense, GRU, LSTM, Bidirectional, Dropout, Input, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "#from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ],
      "source": [
        "# Check if TensorFlow is able to detect the GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Set TensorFlow to use only one GPU\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "\n",
        "        # Enable memory growth\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "        print(\"Using GPU:\", gpus[0])\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set at program startup\n",
        "        print(\"RuntimeError:\", e)\n",
        "else:\n",
        "    raise SystemError(\"GPU device not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oK5js_c4gidk",
        "outputId": "edf107e2-384c-4ce4-a97f-7bffaa9b8ade"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jamaica: “I am HIV”</td>\n",
              "      <td>Jamaïque : J’ai le VIH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's widely acknowledged, in the Caribbean and...</td>\n",
              "      <td>Il est largement reconnu, dans les Caraïbes et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For this woman, however, photographed in the s...</td>\n",
              "      <td>Pour cette femme, cependant, photographiée dan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Bacon writes on her blog:</td>\n",
              "      <td>Comme Bacon écrit sur son blog:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“When I asked to take her picture, I suggested...</td>\n",
              "      <td>“Quand je lui ai demandé de la prendre en phot...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0                                Jamaica: “I am HIV”   \n",
              "1  It's widely acknowledged, in the Caribbean and...   \n",
              "2  For this woman, however, photographed in the s...   \n",
              "3                       As Bacon writes on her blog:   \n",
              "4  “When I asked to take her picture, I suggested...   \n",
              "\n",
              "                                                  fr  \n",
              "0                             Jamaïque : J’ai le VIH  \n",
              "1  Il est largement reconnu, dans les Caraïbes et...  \n",
              "2  Pour cette femme, cependant, photographiée dan...  \n",
              "3                    Comme Bacon écrit sur son blog:  \n",
              "4  “Quand je lui ai demandé de la prendre en phot...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract dataset\n",
        "translation_dataset = load_dataset('Nicolas-BZRD/Parallel_Global_Voices_English_French',\n",
        "                                   split='train').to_pandas()\n",
        "translation_dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q1JjGsN5Ym3P"
      },
      "outputs": [],
      "source": [
        "# Remove line when finishied\n",
        "\n",
        "df = translation_dataset.head(8060)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0A33mW3pEPH"
      },
      "source": [
        "## Data Pre-processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1VsvJZgWW9P",
        "outputId": "a1a1828b-79dd-44a3-fbe6-9d3de62d9a9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\pacho\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "C:\\Users\\pacho\\AppData\\Local\\Temp\\ipykernel_24056\\2695840912.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['en'] = df['en'].apply(clean_text)\n",
            "C:\\Users\\pacho\\AppData\\Local\\Temp\\ipykernel_24056\\2695840912.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['fr'] = df['fr'].apply(clean_text)\n",
            "C:\\Users\\pacho\\AppData\\Local\\Temp\\ipykernel_24056\\2695840912.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['en_tokens'] = df['en'].apply(word_tokenize)\n",
            "C:\\Users\\pacho\\AppData\\Local\\Temp\\ipykernel_24056\\2695840912.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['fr_tokens'] = df['fr'].apply(word_tokenize)\n",
            "C:\\Users\\pacho\\AppData\\Local\\Temp\\ipykernel_24056\\2695840912.py:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(subset=['en', 'fr'], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# First step - Data Pre-processing\n",
        "\n",
        "# nltk downloads\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define a cleaning function\n",
        "def clean_text(text):\n",
        "    return clean(text,\n",
        "                 fix_unicode=True,               # fix various unicode errors\n",
        "                 to_ascii=True,                  # transliterate to closest ASCII representation\n",
        "                 lower=True,                     # lowercase text\n",
        "                 no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
        "                 no_urls=True,                   # replace all URLs with a special token\n",
        "                 no_emails=True,                 # replace all email addresses with a special token\n",
        "                 no_phone_numbers=True,          # replace all phone numbers with a special token\n",
        "                 no_numbers=False,               # replace all numbers with a special token\n",
        "                 no_digits=False,                # replace all digits with a special token\n",
        "                 no_currency_symbols=True,       # replace all currency symbols with a special token\n",
        "                 no_punct=True,                  # remove punctuations\n",
        "                 replace_with_punct=\"\",          # replace punctuations with this character\n",
        "                 replace_with_url=\"<URL>\",\n",
        "                 replace_with_email=\"<EMAIL>\",\n",
        "                 replace_with_phone_number=\"<PHONE>\",\n",
        "                 replace_with_number=\"<NUMBER>\",\n",
        "                 replace_with_digit=\"<DIGIT>\",\n",
        "                 replace_with_currency_symbol=\"<CUR>\",\n",
        "                 lang=\"en\")\n",
        "\n",
        "# Apply cleaning function to both English and French columns\n",
        "df['en'] = df['en'].apply(clean_text)\n",
        "df['fr'] = df['fr'].apply(clean_text)\n",
        "\n",
        "# Tokenization\n",
        "df['en_tokens'] = df['en'].apply(word_tokenize)\n",
        "df['fr_tokens'] = df['fr'].apply(word_tokenize)\n",
        "\n",
        "# Handling missing data\n",
        "df.dropna(subset=['en', 'fr'], inplace=True)\n",
        "\n",
        "# Save the preprocessed data\n",
        "df.to_csv('preprocessed_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dknJrE0jY49t"
      },
      "outputs": [],
      "source": [
        "# Second step - Data Transformation for Training\n",
        "\n",
        "# Tokenization\n",
        "tokenizer_en = Tokenizer()\n",
        "tokenizer_en.fit_on_texts(df['en_tokens'])\n",
        "tokenizer_fr = Tokenizer()\n",
        "tokenizer_fr.fit_on_texts(df['fr_tokens'])\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences_en = tokenizer_en.texts_to_sequences(df['en_tokens'])\n",
        "sequences_fr = tokenizer_fr.texts_to_sequences(df['fr_tokens'])\n",
        "\n",
        "# Padding sequences\n",
        "max_len = max(max(len(s) for s in sequences_en), max(len(s) for s in sequences_fr))\n",
        "sequences_en = pad_sequences(sequences_en, maxlen=max_len, padding='post')\n",
        "sequences_fr = pad_sequences(sequences_fr, maxlen=max_len, padding='post')\n",
        "\n",
        "# Splitting the data\n",
        "split = int(len(sequences_en) * 0.8)\n",
        "trainX, testX = sequences_en[:split], sequences_en[split:]\n",
        "trainY, testY = sequences_fr[:split], sequences_fr[split:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kseUIUXIb45Y"
      },
      "outputs": [],
      "source": [
        "# Third step - Reshape data for feeding into model (French words)\n",
        "trainY = trainY.reshape(trainY.shape[0], trainY.shape[1], 1)\n",
        "testY = testY.reshape(testY.shape[0], testY.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5ANTSUdAl1_5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<--- Data Preprocessed Summary: --->\n",
            "Max English sentence length: 121\n",
            "Max French sentence length: 121\n",
            "English vocabulary size: 16619\n",
            "French vocabulary size: 20767\n"
          ]
        }
      ],
      "source": [
        "# Fourth Step - Some relevant information after pre-processing and transforming\n",
        "max_english_sequence_length = sequences_en.shape[1]\n",
        "max_french_sequence_length = sequences_fr.shape[1]\n",
        "english_vocab_size = len(tokenizer_en.word_index)\n",
        "french_vocab_size = len(tokenizer_fr.word_index)\n",
        "\n",
        "print('<--- Data Preprocessed Summary: --->')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2QXSWTSi854"
      },
      "source": [
        "----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgV-OowJi_Wo"
      },
      "source": [
        "## Model Approach 1: Simple RNN, GRU and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dQ1U5Y68eWdW"
      },
      "outputs": [],
      "source": [
        "# Testing Module - Models\n",
        "\n",
        "def translate_sequence(seq, tokenizer):\n",
        "    \"\"\" Translates a sequence of integers back into text using the tokenizer. \"\"\"\n",
        "    words = [tokenizer.index_word.get(idx, '') for idx in seq]\n",
        "    return ' '.join(words).strip()\n",
        "\n",
        "def predict_and_compare(index, testX, model, tokenizer_en, tokenizer_fr):\n",
        "    \"\"\" Predicts translation for a given index in the test set and compares with the ground truth. \"\"\"\n",
        "    input_seq = testX[index:index+1]\n",
        "    prediction = model.predict(input_seq)\n",
        "\n",
        "    # Converting the prediction to a sequence of integers\n",
        "    predicted_seq = np.argmax(prediction, axis=-1)[0]\n",
        "\n",
        "    # Reverse tokenization (converting sequences back to words)\n",
        "    input_text = translate_sequence(input_seq[0], tokenizer_en)\n",
        "    predicted_text = translate_sequence(predicted_seq, tokenizer_fr)\n",
        "    ground_truth_text = translate_sequence(testY[index].flatten(), tokenizer_fr)\n",
        "\n",
        "    print(\"Input (English):\", input_text)\n",
        "    print(\"Predicted (French):\", predicted_text)\n",
        "    print(\"Ground Truth (French):\", ground_truth_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "IiyExGsibDRF"
      },
      "outputs": [],
      "source": [
        "# Model Section - First Model RNN\n",
        "\n",
        "def simple_rnn(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(SimpleRNN(64, return_sequences=True))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w473VlYnb1sd",
        "outputId": "a61bfe6f-7711-4344-f829-d3448e1bc77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "151/151 [==============================] - 85s 552ms/step - loss: 3.5048 - accuracy: 0.8795 - val_loss: 1.1226 - val_accuracy: 0.8945\n",
            "Epoch 2/10\n",
            "151/151 [==============================] - 69s 455ms/step - loss: 1.2081 - accuracy: 0.8918 - val_loss: 1.2799 - val_accuracy: 0.8873\n",
            "Epoch 3/10\n",
            "151/151 [==============================] - 73s 484ms/step - loss: 1.4180 - accuracy: 0.8824 - val_loss: 1.4270 - val_accuracy: 0.8759\n",
            "Epoch 4/10\n",
            "151/151 [==============================] - 64s 427ms/step - loss: 0.8933 - accuracy: 0.8969 - val_loss: 0.8564 - val_accuracy: 0.8944\n",
            "Epoch 5/10\n",
            "151/151 [==============================] - 78s 515ms/step - loss: 0.8085 - accuracy: 0.8976 - val_loss: 0.8392 - val_accuracy: 0.8946\n",
            "Epoch 6/10\n",
            "151/151 [==============================] - 73s 486ms/step - loss: 0.7956 - accuracy: 0.8982 - val_loss: 0.8356 - val_accuracy: 0.8950\n",
            "Epoch 7/10\n",
            "151/151 [==============================] - 70s 464ms/step - loss: 0.7891 - accuracy: 0.8986 - val_loss: 0.8347 - val_accuracy: 0.8952\n",
            "Epoch 8/10\n",
            "151/151 [==============================] - 76s 503ms/step - loss: 0.7836 - accuracy: 0.8989 - val_loss: 0.8350 - val_accuracy: 0.8951\n",
            "Epoch 9/10\n",
            "151/151 [==============================] - 72s 476ms/step - loss: 0.7783 - accuracy: 0.8993 - val_loss: 0.8349 - val_accuracy: 0.8954\n",
            "Epoch 10/10\n",
            "151/151 [==============================] - 69s 460ms/step - loss: 0.7727 - accuracy: 0.8997 - val_loss: 0.8357 - val_accuracy: 0.8953\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d0229844070>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Testing simple RNN\n",
        "\n",
        "simple_rnn_instance = simple_rnn(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "simple_rnn_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3HUxhPgev4D",
        "outputId": "10b2d72c-db0a-4175-9b4d-17808f7e4c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 235ms/step\n",
            "Input (English): you spend only a portion of your year in morocco\n",
            "Predicted (French): le que a a de de de de de\n",
            "Ground Truth (French): vous ne passez quune partie de lannee au maroc\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Input (English): what do you do the rest of the time\n",
            "Predicted (French): le le le la la\n",
            "Ground Truth (French): que faitesvous le reste du temps\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Input (English): what do you do to relax\n",
            "Predicted (French): le le le la de\n",
            "Ground Truth (French): comment vous detendezvous\n"
          ]
        }
      ],
      "source": [
        "# Predicting with simple RNN (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=simple_rnn_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "-ySNEVP6c80S"
      },
      "outputs": [],
      "source": [
        "# Model Section - First Model GRU\n",
        "\n",
        "def simple_gru(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(GRU(64, return_sequences=True))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj2bIQe3dIY9",
        "outputId": "3d9cec1d-fb9b-4eba-d5ce-6e43118e32ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "151/151 [==============================] - 47s 301ms/step - loss: 3.6132 - accuracy: 0.8912 - val_loss: 1.0734 - val_accuracy: 0.8945\n",
            "Epoch 2/10\n",
            "151/151 [==============================] - 40s 264ms/step - loss: 0.9639 - accuracy: 0.8973 - val_loss: 0.9271 - val_accuracy: 0.8945\n",
            "Epoch 3/10\n",
            "151/151 [==============================] - 39s 260ms/step - loss: 0.8417 - accuracy: 0.8973 - val_loss: 0.8474 - val_accuracy: 0.8947\n",
            "Epoch 4/10\n",
            "151/151 [==============================] - 39s 259ms/step - loss: 0.8015 - accuracy: 0.8980 - val_loss: 0.8359 - val_accuracy: 0.8955\n",
            "Epoch 5/10\n",
            "151/151 [==============================] - 43s 287ms/step - loss: 0.7914 - accuracy: 0.8990 - val_loss: 0.8332 - val_accuracy: 0.8957\n",
            "Epoch 6/10\n",
            "151/151 [==============================] - 38s 255ms/step - loss: 0.7855 - accuracy: 0.8996 - val_loss: 0.8332 - val_accuracy: 0.8957\n",
            "Epoch 7/10\n",
            "151/151 [==============================] - 39s 256ms/step - loss: 0.7806 - accuracy: 0.8998 - val_loss: 0.8352 - val_accuracy: 0.8957\n",
            "Epoch 8/10\n",
            "151/151 [==============================] - 39s 256ms/step - loss: 0.7760 - accuracy: 0.9000 - val_loss: 0.8370 - val_accuracy: 0.8957\n",
            "Epoch 9/10\n",
            "151/151 [==============================] - 39s 256ms/step - loss: 0.7715 - accuracy: 0.9002 - val_loss: 0.8402 - val_accuracy: 0.8957\n",
            "Epoch 10/10\n",
            "151/151 [==============================] - 43s 284ms/step - loss: 0.7670 - accuracy: 0.9004 - val_loss: 0.8447 - val_accuracy: 0.8957\n",
            "1/1 [==============================] - 0s 308ms/step\n",
            "Input (English): you spend only a portion of your year in morocco\n",
            "Predicted (French): je  de de de de\n",
            "Ground Truth (French): vous ne passez quune partie de lannee au maroc\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Input (English): what do you do the rest of the time\n",
            "Predicted (French): il de de\n",
            "Ground Truth (French): que faitesvous le reste du temps\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Input (English): what do you do to relax\n",
            "Predicted (French): il de de\n",
            "Ground Truth (French): comment vous detendezvous\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Testing simple GRU\n",
        "\n",
        "simple_gru_instance = simple_gru(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "simple_gru_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WbD6hyAktdf"
      },
      "outputs": [],
      "source": [
        "# Predicting with simple GRU (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=simple_gru_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vYRcHMsNdad8"
      },
      "outputs": [],
      "source": [
        "# Model Section - First Model LSTM\n",
        "\n",
        "def simple_lstm(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(LSTM(64, return_sequences=True))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv3hkzq1dvyB",
        "outputId": "1ddad33c-e223-4d91-873f-9f70c0cd198a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "151/151 [==============================] - 46s 290ms/step - loss: 3.7090 - accuracy: 0.8854 - val_loss: 1.1075 - val_accuracy: 0.8945\n",
            "Epoch 2/10\n",
            "151/151 [==============================] - 44s 292ms/step - loss: 1.0214 - accuracy: 0.8973 - val_loss: 0.9273 - val_accuracy: 0.8945\n",
            "Epoch 3/10\n",
            "151/151 [==============================] - 44s 292ms/step - loss: 0.8459 - accuracy: 0.8973 - val_loss: 0.8523 - val_accuracy: 0.8945\n",
            "Epoch 4/10\n",
            "151/151 [==============================] - 44s 294ms/step - loss: 0.8076 - accuracy: 0.8979 - val_loss: 0.8398 - val_accuracy: 0.8952\n",
            "Epoch 5/10\n",
            "151/151 [==============================] - 40s 263ms/step - loss: 0.7930 - accuracy: 0.8992 - val_loss: 0.8353 - val_accuracy: 0.8955\n",
            "Epoch 6/10\n",
            "151/151 [==============================] - 43s 286ms/step - loss: 0.7826 - accuracy: 0.8999 - val_loss: 0.8357 - val_accuracy: 0.8950\n",
            "Epoch 7/10\n",
            "151/151 [==============================] - 44s 290ms/step - loss: 0.7754 - accuracy: 0.9001 - val_loss: 0.8364 - val_accuracy: 0.8950\n",
            "Epoch 8/10\n",
            "151/151 [==============================] - 43s 285ms/step - loss: 0.7699 - accuracy: 0.9004 - val_loss: 0.8431 - val_accuracy: 0.8952\n",
            "Epoch 9/10\n",
            "151/151 [==============================] - 43s 285ms/step - loss: 0.7638 - accuracy: 0.9007 - val_loss: 0.8434 - val_accuracy: 0.8951\n",
            "Epoch 10/10\n",
            "151/151 [==============================] - 43s 285ms/step - loss: 0.7590 - accuracy: 0.9010 - val_loss: 0.8522 - val_accuracy: 0.8957\n",
            "1/1 [==============================] - 1s 812ms/step\n",
            "Input (English): you spend only a portion of your year in morocco\n",
            "Predicted (French): il  de de de de\n",
            "Ground Truth (French): vous ne passez quune partie de lannee au maroc\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Input (English): what do you do the rest of the time\n",
            "Predicted (French): il\n",
            "Ground Truth (French): que faitesvous le reste du temps\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Input (English): what do you do to relax\n",
            "Predicted (French): il\n",
            "Ground Truth (French): comment vous detendezvous\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Testing simple LSTM\n",
        "\n",
        "simple_lstm_instance = simple_lstm(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "simple_lstm_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtuFscCkkxoB"
      },
      "outputs": [],
      "source": [
        "# Predicting with simple LSTM (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=simple_lstm_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Of854ddjHUu"
      },
      "source": [
        "## Model Approach 2: Bidirectional RNN, GRU and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "YJNhZchMjKPZ"
      },
      "outputs": [],
      "source": [
        "# Model Section - Bidirectional RNN\n",
        "\n",
        "def bd_rnn(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(Bidirectional(SimpleRNN(64, return_sequences=True)))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usk4OZo0j14U",
        "outputId": "db3c45f9-d3f1-4a3e-d2fc-7f76adf61bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "151/151 [==============================] - 117s 757ms/step - loss: 3.2448 - accuracy: 0.8211 - val_loss: 0.9929 - val_accuracy: 0.8945\n",
            "Epoch 2/10\n",
            "151/151 [==============================] - 110s 729ms/step - loss: 0.8464 - accuracy: 0.8972 - val_loss: 0.8513 - val_accuracy: 0.8945\n",
            "Epoch 3/10\n",
            "151/151 [==============================] - 96s 639ms/step - loss: 0.8083 - accuracy: 0.8977 - val_loss: 0.8476 - val_accuracy: 0.8944\n",
            "Epoch 4/10\n",
            "151/151 [==============================] - 97s 644ms/step - loss: 0.7998 - accuracy: 0.8980 - val_loss: 0.8439 - val_accuracy: 0.8944\n",
            "Epoch 5/10\n",
            "151/151 [==============================] - 103s 682ms/step - loss: 0.7929 - accuracy: 0.8981 - val_loss: 0.8426 - val_accuracy: 0.8946\n",
            "Epoch 6/10\n",
            "151/151 [==============================] - 97s 641ms/step - loss: 0.7868 - accuracy: 0.8986 - val_loss: 0.8417 - val_accuracy: 0.8948\n",
            "Epoch 7/10\n",
            "151/151 [==============================] - 93s 612ms/step - loss: 0.7818 - accuracy: 0.8989 - val_loss: 0.8417 - val_accuracy: 0.8950\n",
            "Epoch 8/10\n",
            "151/151 [==============================] - 91s 600ms/step - loss: 0.7775 - accuracy: 0.8992 - val_loss: 0.8424 - val_accuracy: 0.8951\n",
            "Epoch 9/10\n",
            "151/151 [==============================] - 92s 608ms/step - loss: 0.7730 - accuracy: 0.8995 - val_loss: 0.8425 - val_accuracy: 0.8954\n",
            "Epoch 10/10\n",
            "151/151 [==============================] - 109s 719ms/step - loss: 0.7684 - accuracy: 0.9000 - val_loss: 0.8433 - val_accuracy: 0.8958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d02732bf400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 282ms/step\n",
            "Input (English): you spend only a portion of your year in morocco\n",
            "Predicted (French): il le le le le\n",
            "Ground Truth (French): vous ne passez quune partie de lannee au maroc\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Input (English): what do you do the rest of the time\n",
            "Predicted (French): le le le le\n",
            "Ground Truth (French): que faitesvous le reste du temps\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Input (English): what do you do to relax\n",
            "Predicted (French): le le le\n",
            "Ground Truth (French): comment vous detendezvous\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Bi-Directional RNN\n",
        "\n",
        "bd_rnn_instance = bd_rnn(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "bd_rnn_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzhQiu3yoDm9"
      },
      "outputs": [],
      "source": [
        "# Predicting with Bi-Directional RNN (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=bd_rnn_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LjwRnxjokGB3"
      },
      "outputs": [],
      "source": [
        "# Model Section - Bidirectional GRU\n",
        "\n",
        "def bd_gru(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(Bidirectional(GRU(64, return_sequences=True)))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcOqgbZdkLVD",
        "outputId": "602f8d64-b102-422e-893c-0497c5f1d634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "151/151 [==============================] - 61s 365ms/step - loss: 2.8683 - accuracy: 0.8854 - val_loss: 0.9059 - val_accuracy: 0.8945\n",
            "Epoch 2/10\n",
            "151/151 [==============================] - 45s 301ms/step - loss: 0.8174 - accuracy: 0.8975 - val_loss: 0.8372 - val_accuracy: 0.8946\n",
            "Epoch 3/10\n",
            "151/151 [==============================] - 49s 326ms/step - loss: 0.7954 - accuracy: 0.8983 - val_loss: 0.8407 - val_accuracy: 0.8946\n",
            "Epoch 4/10\n",
            "151/151 [==============================] - 49s 322ms/step - loss: 0.7904 - accuracy: 0.8989 - val_loss: 0.8432 - val_accuracy: 0.8947\n",
            "Epoch 5/10\n",
            "151/151 [==============================] - 49s 322ms/step - loss: 0.7869 - accuracy: 0.8994 - val_loss: 0.8480 - val_accuracy: 0.8948\n",
            "Epoch 6/10\n",
            "151/151 [==============================] - 45s 295ms/step - loss: 0.7835 - accuracy: 0.8997 - val_loss: 0.8526 - val_accuracy: 0.8949\n",
            "Epoch 7/10\n",
            "151/151 [==============================] - 44s 292ms/step - loss: 0.7809 - accuracy: 0.8999 - val_loss: 0.8606 - val_accuracy: 0.8949\n",
            "Epoch 8/10\n",
            "151/151 [==============================] - 44s 292ms/step - loss: 0.7776 - accuracy: 0.9001 - val_loss: 0.8662 - val_accuracy: 0.8950\n",
            "Epoch 9/10\n",
            "151/151 [==============================] - 48s 318ms/step - loss: 0.7740 - accuracy: 0.9002 - val_loss: 0.8702 - val_accuracy: 0.8949\n",
            "Epoch 10/10\n",
            "117/151 [======================>.......] - ETA: 8s - loss: 0.7735 - accuracy: 0.8998"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Bi-Directional GRU\n",
        "\n",
        "bd_gru_instance = bd_gru(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "bd_gru_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNilM5Laojcu"
      },
      "outputs": [],
      "source": [
        "# Predicting with Bi-Directional GRU (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=bd_gru_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nrVkgBpkV12"
      },
      "outputs": [],
      "source": [
        "# Model Section - Bidirectional LSTM\n",
        "\n",
        "def bd_lstm(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml4Ht0SckbfF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Testing Bi-Directional LSTM\n",
        "\n",
        "bd_lstm_instance = bd_lstm(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "bd_lstm_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVjZ8H-dolPt"
      },
      "outputs": [],
      "source": [
        "# Predicting with Bi-Directional LSTM (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=bd_lstm_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuYzoQ3AncuM"
      },
      "source": [
        "## Model Approach 3: Bidirectional RNN, GRU and LSTM - More Complex Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y17Oraf_n1kA"
      },
      "outputs": [],
      "source": [
        "def bd_comp_rnn(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(Bidirectional(SimpleRNN(64, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(SimpleRNN(32, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(SimpleRNN(32, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HezxPc2n9Nk"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Testing Bi-Directional Complex RNN\n",
        "\n",
        "bd_comp_rnn_instance = bd_comp_rnn(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "bd_comp_rnn_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxWaxBOioNXZ"
      },
      "outputs": [],
      "source": [
        "# Predicting Bi-Directional Complex RNN (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=bd_comp_rnn_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRBV7k5mn1rs"
      },
      "outputs": [],
      "source": [
        "def bd_comp_gru(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(Bidirectional(GRU(64, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(GRU(32, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(GRU(32, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBp40XcVoRrh"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Testing Bi-Directional Complex GRU\n",
        "\n",
        "bd_comp_gru_instance = bd_comp_gru(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "bd_comp_gru_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqj3MPAIoULg"
      },
      "outputs": [],
      "source": [
        "# Predicting Bi-Directional Complex GRU (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=bd_comp_rnn_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "alJD0RVgngwe"
      },
      "outputs": [],
      "source": [
        "def bd_comp_lstm(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Define structure of the model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "  model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hU0A3cA9oXvA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "101/101 [==============================] - 25s 175ms/step - loss: 5.1413 - accuracy: 0.8121 - val_loss: 1.7728 - val_accuracy: 0.8258\n",
            "Epoch 2/10\n",
            "101/101 [==============================] - 15s 149ms/step - loss: 1.6303 - accuracy: 0.8253 - val_loss: 1.4493 - val_accuracy: 0.8258\n",
            "Epoch 3/10\n",
            "101/101 [==============================] - 15s 146ms/step - loss: 1.3955 - accuracy: 0.8256 - val_loss: 1.3829 - val_accuracy: 0.8258\n",
            "Epoch 4/10\n",
            "101/101 [==============================] - 14s 144ms/step - loss: 1.3471 - accuracy: 0.8288 - val_loss: 1.3782 - val_accuracy: 0.8291\n",
            "Epoch 5/10\n",
            "101/101 [==============================] - 14s 140ms/step - loss: 1.3262 - accuracy: 0.8309 - val_loss: 1.3806 - val_accuracy: 0.8282\n",
            "Epoch 6/10\n",
            "101/101 [==============================] - 14s 141ms/step - loss: 1.3139 - accuracy: 0.8314 - val_loss: 1.3874 - val_accuracy: 0.8276\n",
            "Epoch 7/10\n",
            "101/101 [==============================] - 14s 141ms/step - loss: 1.3045 - accuracy: 0.8319 - val_loss: 1.3964 - val_accuracy: 0.8253\n",
            "Epoch 8/10\n",
            "101/101 [==============================] - 16s 156ms/step - loss: 1.2971 - accuracy: 0.8322 - val_loss: 1.4061 - val_accuracy: 0.8263\n",
            "Epoch 9/10\n",
            "101/101 [==============================] - 15s 150ms/step - loss: 1.2915 - accuracy: 0.8324 - val_loss: 1.4136 - val_accuracy: 0.8246\n",
            "Epoch 10/10\n",
            "101/101 [==============================] - 14s 142ms/step - loss: 1.2871 - accuracy: 0.8327 - val_loss: 1.4197 - val_accuracy: 0.8261\n",
            "CPU times: total: 31.4 s\n",
            "Wall time: 2min 38s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2bdbd09de50>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Bi-Directional Complex LSTM\n",
        "\n",
        "bd_comp_lstm_instance = bd_comp_lstm(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "bd_comp_lstm_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "eSdynoMxoeg3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Input (English): do you believe uganda has a free press\n",
            "Predicted (French): le de de de de\n",
            "Ground Truth (French): croyezvous que louganda a une presse libre\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
            "Predicted (French): le de de de de de de de de de de de de de de de de de de de\n",
            "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
            "Predicted (French): le de de de de de de de de de de de de de de de de de de de de de de de de de de\n",
            "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
          ]
        }
      ],
      "source": [
        "# Predicting Bi-Directional Complex LSTM (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare(index=i, testX=testX, model=bd_comp_lstm_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0dBAUA7qjJq"
      },
      "source": [
        "## Model Approach 4: Auto-Encoders with RNN, GRU and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need to define the encoder and decoder models testing function separately\n",
        "\n",
        "def predict_and_compare_auto_en(index, testX, testY, model, tokenizer_en, tokenizer_fr):\n",
        "    \"\"\" Predicts translation for a given index in the test set and compares with the ground truth. \"\"\"\n",
        "    input_seq_X = testX[index:index+1]\n",
        "    input_seq_Y = testY[index:index+1]\n",
        "    prediction = model.predict([input_seq_X, input_seq_Y])\n",
        "\n",
        "    # Converting the prediction to a sequence of integers\n",
        "    predicted_seq = np.argmax(prediction, axis=-1)[0]\n",
        "\n",
        "    # Reverse tokenization (converting sequences back to words)\n",
        "    input_text = translate_sequence(input_seq_X[0], tokenizer_en)\n",
        "    predicted_text = translate_sequence(predicted_seq, tokenizer_fr)\n",
        "    ground_truth_text = translate_sequence(testY[index].flatten(), tokenizer_fr)\n",
        "\n",
        "    print(\"Input (English):\", input_text)\n",
        "    print(\"Predicted (French):\", predicted_text)\n",
        "    print(\"Ground Truth (French):\", ground_truth_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encoder_decoder_rnn(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Encoder\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  enc_emb = Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64)(encoder_inputs)\n",
        "  encoder_rnn = SimpleRNN(64, return_state=True)\n",
        "  encoder_outputs, state = encoder_rnn(enc_emb)\n",
        "\n",
        "  # Decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  dec_emb_layer = Embedding(input_dim=len(tokenizer_fr.word_index) + 1, output_dim=64)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "  decoder_rnn = SimpleRNN(64, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _= decoder_rnn(dec_emb, initial_state=state)\n",
        "  decoder_dense = Dense(len(tokenizer_fr.word_index) + 1, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # Build Final Model\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  # Comple the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, None, 64)     1063680     ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)        (None, None, 64)     1329152     ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " simple_rnn_1 (SimpleRNN)       [(None, 64),         8256        ['embedding_7[0][0]']            \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " simple_rnn_2 (SimpleRNN)       [(None, None, 64),   8256        ['embedding_8[0][0]',            \n",
            "                                 (None, 64)]                      'simple_rnn_1[0][1]']           \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, None, 20768)  1349920     ['simple_rnn_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,759,264\n",
            "Trainable params: 3,759,264\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 27s 311ms/step - loss: 5.7953 - accuracy: 0.7920 - val_loss: 1.9868 - val_accuracy: 0.8310\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 23s 279ms/step - loss: 1.7904 - accuracy: 0.8238 - val_loss: 1.6926 - val_accuracy: 0.8310\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 23s 279ms/step - loss: 1.7278 - accuracy: 0.8238 - val_loss: 1.6819 - val_accuracy: 0.8310\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 22s 276ms/step - loss: 1.6433 - accuracy: 0.8238 - val_loss: 1.4011 - val_accuracy: 0.8310\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 23s 278ms/step - loss: 1.3440 - accuracy: 0.8238 - val_loss: 1.2601 - val_accuracy: 0.8310\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 24s 295ms/step - loss: 1.2376 - accuracy: 0.8245 - val_loss: 1.1779 - val_accuracy: 0.8379\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 24s 295ms/step - loss: 1.1618 - accuracy: 0.8383 - val_loss: 1.1221 - val_accuracy: 0.8464\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 23s 289ms/step - loss: 1.0946 - accuracy: 0.8447 - val_loss: 1.0651 - val_accuracy: 0.8566\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 24s 296ms/step - loss: 1.0293 - accuracy: 0.8591 - val_loss: 1.0091 - val_accuracy: 0.8699\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 24s 298ms/step - loss: 0.9660 - accuracy: 0.8725 - val_loss: 0.9536 - val_accuracy: 0.8831\n",
            "CPU times: total: 1min 6s\n",
            "Wall time: 3min 56s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2be8dcafdc0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Encoder-Decoder RNN\n",
        "\n",
        "en_dec_rnn_instance = encoder_decoder_rnn(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "\n",
        "# Summary of the model\n",
        "en_dec_rnn_instance.summary()\n",
        "en_dec_rnn_instance.fit([trainX, trainY], np.expand_dims(trainY, -1), epochs=10, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 242ms/step\n",
            "Input (English): do you believe uganda has a free press\n",
            "Predicted (French): voici que  a une\n",
            "Ground Truth (French): croyezvous que louganda a une presse libre\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
            "Predicted (French): a les le region les region  sont  au ete the la monde de la region de region de ete du  de\n",
            "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
            "Predicted (French): il les  ont pays  a  les region de ces de pays dans la region de  dans  de  sont  les ces  de ete\n",
            "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
          ]
        }
      ],
      "source": [
        "# Predicting Encoder-Decoder RNN (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare_auto_en(index=i, testX=testX, testY=testY, model=en_dec_rnn_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encoder_decoder_gru(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Encoder\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  enc_emb = Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64)(encoder_inputs)\n",
        "  encoder_gru = GRU(64, return_state=True)\n",
        "  encoder_outputs, state = encoder_gru(enc_emb)\n",
        "\n",
        "  # Decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  dec_emb_layer = Embedding(input_dim=len(tokenizer_fr.word_index) + 1, output_dim=64)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "  decoder_gru = GRU(64, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _= decoder_gru(dec_emb, initial_state=state)\n",
        "  decoder_dense = Dense(len(tokenizer_fr.word_index) + 1, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # Build Final Model\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  # Comple the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, None, 64)     1063680     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, None, 64)     1329152     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, 64),         24960       ['embedding_4[0][0]']            \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, None, 64),   24960       ['embedding_5[0][0]',            \n",
            "                                 (None, 64)]                      'gru_1[0][1]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 20768)  1349920     ['gru_2[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,792,672\n",
            "Trainable params: 3,792,672\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 12s 113ms/step - loss: 5.8908 - accuracy: 0.8040 - val_loss: 1.7965 - val_accuracy: 0.8310\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 8s 102ms/step - loss: 1.6866 - accuracy: 0.8238 - val_loss: 1.5204 - val_accuracy: 0.8310\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 8s 102ms/step - loss: 1.4984 - accuracy: 0.8238 - val_loss: 1.4007 - val_accuracy: 0.8310\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 8s 105ms/step - loss: 1.3803 - accuracy: 0.8238 - val_loss: 1.3161 - val_accuracy: 0.8310\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 9s 106ms/step - loss: 1.3094 - accuracy: 0.8240 - val_loss: 1.2681 - val_accuracy: 0.8323\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 8s 104ms/step - loss: 1.2525 - accuracy: 0.8276 - val_loss: 1.2157 - val_accuracy: 0.8368\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 9s 107ms/step - loss: 1.1983 - accuracy: 0.8315 - val_loss: 1.1747 - val_accuracy: 0.8396\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 9s 106ms/step - loss: 1.1535 - accuracy: 0.8370 - val_loss: 1.1355 - val_accuracy: 0.8460\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 9s 107ms/step - loss: 1.1053 - accuracy: 0.8465 - val_loss: 1.0898 - val_accuracy: 0.8596\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 9s 106ms/step - loss: 1.0487 - accuracy: 0.8601 - val_loss: 1.0376 - val_accuracy: 0.8765\n",
            "CPU times: total: 14.3 s\n",
            "Wall time: 1min 29s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2bd34c18670>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Encoder-Decoder GRU\n",
        "\n",
        "en_dec_gru_instance = encoder_decoder_gru(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "\n",
        "# Summary of the model\n",
        "en_dec_gru_instance.summary()\n",
        "en_dec_gru_instance.fit([trainX, trainY], np.expand_dims(trainY, -1), epochs=10, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 601ms/step\n",
            "Input (English): do you believe uganda has a free press\n",
            "Predicted (French): blogueur que blogueur a une blogueur blogueur\n",
            "Ground Truth (French): croyezvous que louganda a une presse libre\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
            "Predicted (French): a le le blogueur les blogueur blogueur un est un ete ces la ete de la blogueur et blogueur de du du de en ete\n",
            "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
            "Predicted (French): les les blogueur les blogueur nous a ete les blogueur de blogueur en se pas la blogueur de de pas blogueur de ete un de la blog pas de leurs\n",
            "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
          ]
        }
      ],
      "source": [
        "# Predicting Encoder-Decoder GRU (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare_auto_en(index=i, testX=testX, testY=testY, model=en_dec_gru_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qKhweqwZqhuq"
      },
      "outputs": [],
      "source": [
        "def encoder_decoder_lstm(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Encoder\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  enc_emb = Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64)(encoder_inputs)\n",
        "  encoder_lstm = LSTM(64, return_state=True)\n",
        "  encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "  encoder_states = [state_h, state_c]\n",
        "\n",
        "  # Decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  dec_emb_layer = Embedding(input_dim=len(tokenizer_fr.word_index) + 1, output_dim=64)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "  decoder_lstm = LSTM(64, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "  decoder_dense = Dense(len(tokenizer_fr.word_index) + 1, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # Build Final Model\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  # Comple the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1_gi2VM3s65l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 64)     1063680     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     1329152     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 64),         33024       ['embedding[0][0]']              \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 64),   33024       ['embedding_1[0][0]',            \n",
            "                                 (None, 64),                      'lstm[0][1]',                   \n",
            "                                 (None, 64)]                      'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 20768)  1349920     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,808,800\n",
            "Trainable params: 3,808,800\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 14s 114ms/step - loss: 6.0199 - accuracy: 0.8038 - val_loss: 1.8380 - val_accuracy: 0.8310\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 8s 105ms/step - loss: 1.6834 - accuracy: 0.8238 - val_loss: 1.5057 - val_accuracy: 0.8310\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 9s 106ms/step - loss: 1.4339 - accuracy: 0.8238 - val_loss: 1.3304 - val_accuracy: 0.8310\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 8s 105ms/step - loss: 1.3329 - accuracy: 0.8238 - val_loss: 1.2864 - val_accuracy: 0.8310\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 8s 105ms/step - loss: 1.2942 - accuracy: 0.8254 - val_loss: 1.2584 - val_accuracy: 0.8353\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 9s 107ms/step - loss: 1.2552 - accuracy: 0.8315 - val_loss: 1.2190 - val_accuracy: 0.8391\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 9s 107ms/step - loss: 1.2131 - accuracy: 0.8324 - val_loss: 1.1846 - val_accuracy: 0.8391\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 8s 105ms/step - loss: 1.1796 - accuracy: 0.8324 - val_loss: 1.1582 - val_accuracy: 0.8391\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 9s 106ms/step - loss: 1.1499 - accuracy: 0.8324 - val_loss: 1.1324 - val_accuracy: 0.8392\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 8s 103ms/step - loss: 1.1206 - accuracy: 0.8327 - val_loss: 1.1088 - val_accuracy: 0.8400\n",
            "CPU times: total: 20 s\n",
            "Wall time: 1min 32s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2bc86071160>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Encoder-Decoder LSTM\n",
        "\n",
        "en_dec_lstm = encoder_decoder_lstm(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "\n",
        "# Summary of the model\n",
        "en_dec_lstm.summary()\n",
        "en_dec_lstm.fit([trainX, trainY], np.expand_dims(trainY, -1), epochs=10, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_eQAsxYmtJZd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 503ms/step\n",
            "Input (English): do you believe uganda has a free press\n",
            "Predicted (French): nous de leur de de\n",
            "Ground Truth (French): croyezvous que louganda a une presse libre\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
            "Predicted (French): de de de ete de leur  de  de et  de  de de  de ete de de de  de\n",
            "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
            "Predicted (French): le le leur de aux ete de  de leur de  de  de de  de  de  de  de  de   de\n",
            "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
          ]
        }
      ],
      "source": [
        "# Predicting Encoder-Decoder LSTM (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare_auto_en(index=i, testX=testX, testY=testY, model=en_dec_lstm, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Approach 5: Auto-Encoders with RNN, GRU and LSTM - More Complex Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encoder_decoder_comp_rnn(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Encoder\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  enc_emb = Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64)(encoder_inputs)\n",
        "\n",
        "  # Stacking multiple RNN layers in the encoder\n",
        "  encoder_rnn1 = SimpleRNN(64, return_sequences=True, return_state=True)\n",
        "  encoder_outputs, state = encoder_rnn1(enc_emb)\n",
        "  encoder_rnn2 = SimpleRNN(64, return_state=True)\n",
        "  encoder_outputs, state = encoder_rnn2(encoder_outputs)\n",
        "\n",
        "  # Decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  dec_emb_layer = Embedding(input_dim=len(tokenizer_fr.word_index) + 1, output_dim=64)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # Stacking multiple RNN layers in the decoder\n",
        "  decoder_rnn1 = SimpleRNN(64, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _ = decoder_rnn1(dec_emb, initial_state=state)\n",
        "  decoder_rnn2 = SimpleRNN(64, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _ = decoder_rnn2(decoder_outputs, initial_state=state)\n",
        "\n",
        "  decoder_dense = Dense(len(tokenizer_fr.word_index) + 1, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # Define the model\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_9 (Embedding)        (None, None, 64)     1063680     ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn_3 (SimpleRNN)       [(None, None, 64),   8256        ['embedding_9[0][0]']            \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " embedding_10 (Embedding)       (None, None, 64)     1329152     ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " simple_rnn_4 (SimpleRNN)       [(None, 64),         8256        ['simple_rnn_3[0][0]']           \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " simple_rnn_5 (SimpleRNN)       [(None, None, 64),   8256        ['embedding_10[0][0]',           \n",
            "                                 (None, 64)]                      'simple_rnn_4[0][1]']           \n",
            "                                                                                                  \n",
            " simple_rnn_6 (SimpleRNN)       [(None, None, 64),   8256        ['simple_rnn_5[0][0]',           \n",
            "                                 (None, 64)]                      'simple_rnn_4[0][1]']           \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, None, 20768)  1349920     ['simple_rnn_6[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,775,776\n",
            "Trainable params: 3,775,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 45s 520ms/step - loss: 5.7628 - accuracy: 0.8016 - val_loss: 2.0504 - val_accuracy: 0.8310\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 41s 511ms/step - loss: 2.0271 - accuracy: 0.8138 - val_loss: 1.6987 - val_accuracy: 0.8310\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 44s 547ms/step - loss: 1.7406 - accuracy: 0.8219 - val_loss: 1.4911 - val_accuracy: 0.8310\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 40s 498ms/step - loss: 1.4096 - accuracy: 0.8238 - val_loss: 1.3092 - val_accuracy: 0.8310\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 44s 540ms/step - loss: 1.3142 - accuracy: 0.8260 - val_loss: 1.2718 - val_accuracy: 0.8370\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 39s 484ms/step - loss: 1.2778 - accuracy: 0.8315 - val_loss: 1.2385 - val_accuracy: 0.8389\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 38s 469ms/step - loss: 1.2224 - accuracy: 0.8327 - val_loss: 1.1865 - val_accuracy: 0.8399\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 41s 512ms/step - loss: 1.1751 - accuracy: 0.8335 - val_loss: 1.1587 - val_accuracy: 0.8429\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 45s 560ms/step - loss: 1.1396 - accuracy: 0.8374 - val_loss: 1.1350 - val_accuracy: 0.8457\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 38s 473ms/step - loss: 1.1061 - accuracy: 0.8399 - val_loss: 1.1120 - val_accuracy: 0.8467\n",
            "CPU times: total: 1min 44s\n",
            "Wall time: 6min 57s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2be9010f460>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Encoder-Decoder Complex RNN\n",
        "\n",
        "encoder_decoder_comp_rnn_instance = encoder_decoder_comp_rnn(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "\n",
        "# Summary of the model\n",
        "encoder_decoder_comp_rnn_instance.summary()\n",
        "encoder_decoder_comp_rnn_instance.fit([trainX, trainY], np.expand_dims(trainY, -1), epochs=10, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002BE90325AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 426ms/step\n",
            "Input (English): do you believe uganda has a free press\n",
            "Predicted (French): the que sont de la ete sont\n",
            "Ground Truth (French): croyezvous que louganda a une presse libre\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
            "Predicted (French): le la la ne de blogueur sont que que de ete que de blog de la blog de blogueur de ete que que de blogueur\n",
            "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
            "Predicted (French): le la ne de ne sont de blog de blogueur de blog de ete de la ete de ete de ete de blogueur sont que de un que de blog\n",
            "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
          ]
        }
      ],
      "source": [
        "# Testing Encoder-Decoder Complex RNN (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare_auto_en(index=i, testX=testX, testY=testY, model=encoder_decoder_comp_rnn_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encoder_decoder_comp_gru(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "  # Encoder\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  enc_emb = Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64)(encoder_inputs)\n",
        "\n",
        "  # Stacking multiple GRU layers in the encoder\n",
        "  encoder_gru1 = GRU(64, return_sequences=True, return_state=True)\n",
        "  encoder_outputs, state = encoder_gru1(enc_emb)\n",
        "  encoder_gru2 = GRU(64, return_state=True)\n",
        "  encoder_outputs, state = encoder_gru2(encoder_outputs)\n",
        "\n",
        "  # Decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  dec_emb_layer = Embedding(input_dim=len(tokenizer_fr.word_index) + 1, output_dim=64)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # Stacking multiple GRU layers in the decoder\n",
        "  decoder_gru1 = GRU(64, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _ = decoder_gru1(dec_emb, initial_state=state)\n",
        "  decoder_gru2 = GRU(64, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _ = decoder_gru2(decoder_outputs, initial_state=state)\n",
        "\n",
        "  decoder_dense = Dense(len(tokenizer_fr.word_index) + 1, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # Define the model\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_11 (Embedding)       (None, None, 64)     1063680     ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " input_12 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    [(None, None, 64),   24960       ['embedding_11[0][0]']           \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " embedding_12 (Embedding)       (None, None, 64)     1329152     ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " gru_4 (GRU)                    [(None, 64),         24960       ['gru_3[0][0]']                  \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " gru_5 (GRU)                    [(None, None, 64),   24960       ['embedding_12[0][0]',           \n",
            "                                 (None, 64)]                      'gru_4[0][1]']                  \n",
            "                                                                                                  \n",
            " gru_6 (GRU)                    [(None, None, 64),   24960       ['gru_5[0][0]',                  \n",
            "                                 (None, 64)]                      'gru_4[0][1]']                  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, None, 20768)  1349920     ['gru_6[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,842,592\n",
            "Trainable params: 3,842,592\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 15s 131ms/step - loss: 5.7417 - accuracy: 0.8038 - val_loss: 1.8657 - val_accuracy: 0.8310\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 10s 119ms/step - loss: 1.7058 - accuracy: 0.8238 - val_loss: 1.5297 - val_accuracy: 0.8310\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 10s 121ms/step - loss: 1.5275 - accuracy: 0.8238 - val_loss: 1.4646 - val_accuracy: 0.8310\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 10s 120ms/step - loss: 1.4893 - accuracy: 0.8238 - val_loss: 1.4502 - val_accuracy: 0.8310\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 10s 120ms/step - loss: 1.4626 - accuracy: 0.8238 - val_loss: 1.4157 - val_accuracy: 0.8310\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 10s 120ms/step - loss: 1.3904 - accuracy: 0.8238 - val_loss: 1.3447 - val_accuracy: 0.8310\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 10s 121ms/step - loss: 1.3251 - accuracy: 0.8263 - val_loss: 1.3088 - val_accuracy: 0.8358\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 10s 120ms/step - loss: 1.2964 - accuracy: 0.8294 - val_loss: 1.2925 - val_accuracy: 0.8367\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 10s 121ms/step - loss: 1.2793 - accuracy: 0.8304 - val_loss: 1.2783 - val_accuracy: 0.8374\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 10s 121ms/step - loss: 1.2552 - accuracy: 0.8321 - val_loss: 1.2534 - val_accuracy: 0.8385\n",
            "CPU times: total: 31.8 s\n",
            "Wall time: 1min 43s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2be95ac09a0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Encoder-Decoder Complex GRU\n",
        "\n",
        "encoder_decoder_comp_gru_instance = encoder_decoder_comp_gru(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "\n",
        "# Summary of the model\n",
        "encoder_decoder_comp_gru_instance.summary()\n",
        "encoder_decoder_comp_gru_instance.fit([trainX, trainY], np.expand_dims(trainY, -1), epochs=10, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002BE90045C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 1s 933ms/step\n",
            "Input (English): do you believe uganda has a free press\n",
            "Predicted (French): le de de de de de de\n",
            "Ground Truth (French): croyezvous que louganda a une presse libre\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
            "Predicted (French): le le de de de de de de de de de de de de de de de de de de de de de de de\n",
            "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
            "Predicted (French): le le de de de de de de de de de de de de de de de de de de de de de de de de de  de\n",
            "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
          ]
        }
      ],
      "source": [
        "# Testing Encoder-Decoder Complex GRU (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare_auto_en(index=i, testX=testX, testY=testY, model=encoder_decoder_comp_gru_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encoder_decoder_comp_lstm(tokenizer_en, tokenizer_fr):\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(None,))\n",
        "    enc_emb = Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64)(encoder_inputs)\n",
        "\n",
        "    # Stacking multiple LSTM layers in the encoder\n",
        "    encoder_lstm1 = LSTM(64, return_sequences=True, return_state=True)\n",
        "    encoder_outputs, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "    encoder_lstm2 = LSTM(64, return_state=True)\n",
        "    encoder_outputs, state_h2, state_c2 = encoder_lstm2(encoder_outputs)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(None,))\n",
        "    dec_emb_layer = Embedding(input_dim=len(tokenizer_fr.word_index) + 1, output_dim=64)\n",
        "    dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "    # Stacking multiple LSTM layers in the decoder\n",
        "    decoder_lstm1 = LSTM(64, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm1(dec_emb, initial_state=[state_h1, state_c1])\n",
        "    decoder_lstm2 = LSTM(64, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm2(decoder_outputs, initial_state=[state_h2, state_c2])\n",
        "\n",
        "    decoder_dense = Dense(len(tokenizer_fr.word_index) + 1, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_13 (Embedding)       (None, None, 64)     1063680     ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_14 (Embedding)       (None, None, 64)     1329152     ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, None, 64),   33024       ['embedding_13[0][0]']           \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)                  [(None, None, 64),   33024       ['embedding_14[0][0]',           \n",
            "                                 (None, 64),                      'lstm_5[0][1]',                 \n",
            "                                 (None, 64)]                      'lstm_5[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  [(None, 64),         33024       ['lstm_5[0][0]']                 \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)                  [(None, None, 64),   33024       ['lstm_7[0][0]',                 \n",
            "                                 (None, 64),                      'lstm_6[0][1]',                 \n",
            "                                 (None, 64)]                      'lstm_6[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, None, 20768)  1349920     ['lstm_8[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,874,848\n",
            "Trainable params: 3,874,848\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 16s 150ms/step - loss: 5.8864 - accuracy: 0.8040 - val_loss: 1.8852 - val_accuracy: 0.8310\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 11s 131ms/step - loss: 1.7351 - accuracy: 0.8238 - val_loss: 1.5743 - val_accuracy: 0.8310\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 11s 131ms/step - loss: 1.5483 - accuracy: 0.8238 - val_loss: 1.4300 - val_accuracy: 0.8310\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 10s 125ms/step - loss: 1.3899 - accuracy: 0.8238 - val_loss: 1.3168 - val_accuracy: 0.8310\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 10s 121ms/step - loss: 1.3230 - accuracy: 0.8238 - val_loss: 1.2933 - val_accuracy: 0.8310\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 10s 122ms/step - loss: 1.3031 - accuracy: 0.8265 - val_loss: 1.2827 - val_accuracy: 0.8364\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 10s 122ms/step - loss: 1.2908 - accuracy: 0.8312 - val_loss: 1.2747 - val_accuracy: 0.8384\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 10s 123ms/step - loss: 1.2761 - accuracy: 0.8321 - val_loss: 1.2514 - val_accuracy: 0.8388\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 10s 123ms/step - loss: 1.2308 - accuracy: 0.8323 - val_loss: 1.1915 - val_accuracy: 0.8392\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 10s 122ms/step - loss: 1.1852 - accuracy: 0.8324 - val_loss: 1.1611 - val_accuracy: 0.8393\n",
            "CPU times: total: 27.7 s\n",
            "Wall time: 1min 47s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2be9fc932b0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# Testing Encoder-Decoder Complex LSTM\n",
        "\n",
        "encoder_decoder_comp_lstm_instance = encoder_decoder_comp_lstm(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
        "\n",
        "# Summary of the model\n",
        "encoder_decoder_comp_lstm_instance.summary()\n",
        "encoder_decoder_comp_lstm_instance.fit([trainX, trainY], np.expand_dims(trainY, -1), epochs=10, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Input (English): do you believe uganda has a free press\n",
            "Predicted (French): il de  de de\n",
            "Ground Truth (French): croyezvous que louganda a une presse libre\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
            "Predicted (French): de de de de de   de  de de de de  de de de de de de de de  de\n",
            "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
            "Predicted (French): le de de de  de de  de  de  de de de de  de  de  de  de  de   de\n",
            "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
          ]
        }
      ],
      "source": [
        "# Testing Encoder-Decoder Complex LSTM (First 3 Test Samples)\n",
        "for i in range(3):\n",
        "    predict_and_compare_auto_en(index=i, testX=testX, testY=testY, model=encoder_decoder_comp_lstm_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5Uu6QDWVDI"
      },
      "source": [
        "____________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUiV0wpclv_l"
      },
      "outputs": [],
      "source": [
        "# End of notebook"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
