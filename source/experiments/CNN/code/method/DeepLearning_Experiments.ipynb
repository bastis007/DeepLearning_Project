{"cells":[{"cell_type":"markdown","metadata":{"id":"Z1-NSByOrC6Z"},"source":["# Deep Learning CNN Model on Colab"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31930,"status":"ok","timestamp":1704548250181,"user":{"displayName":"Bastian Schäfer","userId":"12245161686255893030"},"user_tz":-60},"id":"noqFuAemrAMb","outputId":"3e4e81c9-6e37-42de-fcfa-df3eecf02ca6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = 'drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/'"]},{"cell_type":"markdown","metadata":{"id":"rAZ5YWrPougW"},"source":["## Models"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3760,"status":"ok","timestamp":1704548268383,"user":{"displayName":"Bastian Schäfer","userId":"12245161686255893030"},"user_tz":-60},"id":"jLKZF4uyowdH"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, Concatenate, MaxPooling1D, Dense, Dropout, GlobalMaxPooling1D\n","\n","class CNN_Basic:\n","    def __init__(self, tokenizer_en, tokenizer_fr, max_len, max_vocab_fr_len):\n","        self.tokenizer_en = tokenizer_en\n","        self.tokenizer_fr = tokenizer_fr\n","        self.max_len = max_len\n","        self.max_vocab_fr_len = max_vocab_fr_len\n","\n","    def build_model(self):\n","        # Define Encoder\n","        model = Sequential()\n","        model.add(Embedding(input_dim=len(self.tokenizer_en.word_index) + 1, output_dim=64, input_length=self.max_len))\n","        model.add(Conv1D(256, kernel_size=8, padding='same', activation='relu'))\n","        model.add(MaxPooling1D(pool_size=1, strides=1))\n","        model.add(Conv1D(128, kernel_size=5, padding='same', activation='relu'))\n","        model.add(Dropout(0.5))\n","        model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n","        model.add(MaxPooling1D(pool_size=1, strides=1))\n","        model.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n","        model.add(Dense(100, activation='relu'))\n","        model.add(Dense(len(self.tokenizer_fr.word_index) + 1)),\n","\n","        # Compile the model\n","        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1704548269619,"user":{"displayName":"Bastian Schäfer","userId":"12245161686255893030"},"user_tz":-60},"id":"BKiZFymmw3j9"},"outputs":[],"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Embedding, Conv1D, Concatenate, MaxPooling1D, Dense, Dropout, Flatten, Input, \\\n","    RepeatVector, Reshape\n","\n","class CNN_Auto_Basic:\n","    def __init__(self, tokenizer_en, tokenizer_fr, max_len, max_vocab_fr_len):\n","        self.tokenizer_en = tokenizer_en\n","        self.tokenizer_fr = tokenizer_fr\n","        self.max_len = max_len\n","        self.max_vocab_fr_len = max_vocab_fr_len\n","\n","    def build_model(self):\n","        # Encoder\n","        encoder_inputs = Input(shape=(None,))\n","        enc_emb_layer = Embedding(input_dim=len(self.tokenizer_en.word_index) + 1, output_dim=32)\n","        enc_emb = enc_emb_layer(encoder_inputs)\n","        # Adding conv and pool layers in the encoder\n","        encoder_cnn1 = Conv1D(128, kernel_size=5, padding='same', activation='relu')(enc_emb)\n","        encoder_cnn2 = Conv1D(64, kernel_size=3, padding='same', activation='relu')(encoder_cnn1)\n","        encoder_cnn3 = Conv1D(32, kernel_size=3, padding='same', activation='relu')(encoder_cnn2)\n","\n","        # Decoder\n","        decoder_inputs = Input(shape=(None,))\n","        dec_emb_layer = Embedding(input_dim=len(self.tokenizer_fr.word_index) + 1, output_dim=32)\n","        dec_emb = dec_emb_layer(decoder_inputs)\n","\n","        # Adding conv and pool layers + encoder in the decoder\n","        decoder_cnn1 = Conv1D(128, kernel_size=5, padding='same', activation='relu')(dec_emb)\n","        #encoder_output_repeated = RepeatVector(32)(Flatten()(encoder_cnn3))\n","        #encoder_output_repeated = Reshape((32, 64))(encoder_output_repeated)\n","        #merged_input = Concatenate(axis=-1)([decoder_cnn1, encoder_output_repeated])\n","        decoder_cnn2 = Conv1D(64, kernel_size=3, padding='same', activation='relu')(decoder_cnn1)\n","        decoder_cnn3 = Conv1D(64, kernel_size=3, padding='same', activation='relu')(decoder_cnn2)\n","        decoder_dense = Dense(self.max_vocab_fr_len + 1, activation='softmax')\n","        decoder_outputs = decoder_dense(decoder_cnn3)\n","        # Add to a model\n","        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","        # Compile the model\n","        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model\n"]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Embedding, Conv1D, Concatenate, MaxPooling1D, Dense, Dropout, Flatten, Input, \\\n","    RepeatVector, Reshape\n","\n","\n","class CNN_Auto_Bigger:\n","    def __init__(self, tokenizer_en, tokenizer_fr, max_len, max_vocab_fr_len):\n","        self.tokenizer_en = tokenizer_en\n","        self.tokenizer_fr = tokenizer_fr\n","        self.max_len = max_len\n","        self.max_vocab_fr_len = max_vocab_fr_len\n","\n","    def build_model(self):\n","        # Encoder\n","        encoder_inputs = Input(shape=(None,))\n","        enc_emb_layer = Embedding(input_dim=len(self.tokenizer_en.word_index) + 1, output_dim=32)\n","        enc_emb = enc_emb_layer(encoder_inputs)\n","        # Adding conv and pool layers in the encoder\n","        #encoder_cnn1 = Conv1D(16384, kernel_size=50, padding='same', activation='relu')(enc_emb)\n","        #encoder_cnn2 = Conv1D(8192, kernel_size=20, padding='same', activation='relu')(encoder_cnn1)\n","        #encoder_cnn3 = Conv1D(4096, kernel_size=10, padding='same', activation='relu')(encoder_cnn2)\n","        #encoder_cnn4 = Conv1D(2048, kernel_size=10, padding='same', activation='relu')(encoder_cnn3)\n","        encoder_cnn5 = Conv1D(1024, kernel_size=5, padding='same', activation='relu')(enc_emb)\n","        encoder_cnn6 = Conv1D(512, kernel_size=5, padding='same', activation='relu')(encoder_cnn5)\n","        encoder_cnn7 = Conv1D(256, kernel_size=5, padding='same', activation='relu')(encoder_cnn6)\n","        encoder_cnn8 = Conv1D(128, kernel_size=3, padding='same', activation='relu')(encoder_cnn7)\n","        encoder_cnn9 = Conv1D(64, kernel_size=3, padding='same', activation='relu')(encoder_cnn8)\n","        encoder_cnn10 = Conv1D(32, kernel_size=3, padding='same', activation='relu')(encoder_cnn9)\n","\n","        # Decoder\n","        decoder_inputs = Input(shape=(None,))\n","        dec_emb_layer = Embedding(input_dim=len(self.tokenizer_fr.word_index) + 1, output_dim=32)\n","        dec_emb = dec_emb_layer(decoder_inputs)\n","\n","        # Adding conv and pool layers + encoder in the decoder\n","        #decoder_cnn1 = Conv1D(16384, kernel_size=50, padding='same', activation='relu')(dec_emb)\n","        #encoder_output_repeated = RepeatVector(32)(Flatten()(encoder_cnn3))\n","        #encoder_output_repeated = Reshape((32, 64))(encoder_output_repeated)\n","        #merged_input = Concatenate(axis=-1)([decoder_cnn1, encoder_output_repeated])\n","        #decoder_cnn2 = Conv1D(8192, kernel_size=20, padding='same', activation='relu')(decoder_cnn1)\n","        #decoder_cnn3 = Conv1D(4096, kernel_size=10, padding='same', activation='relu')(decoder_cnn2)\n","        #decoder_cnn4 = Conv1D(2048, kernel_size=10, padding='same', activation='relu')(decoder_cnn3)\n","        decoder_cnn5 = Conv1D(1024, kernel_size=5, padding='same', activation='relu')(dec_emb)\n","        decoder_cnn6 = Conv1D(512, kernel_size=5, padding='same', activation='relu')(decoder_cnn5)\n","        decoder_cnn7 = Conv1D(256, kernel_size=5, padding='same', activation='relu')(decoder_cnn6)\n","        decoder_cnn8 = Conv1D(128, kernel_size=3, padding='same', activation='relu')(decoder_cnn7)\n","        decoder_cnn9 = Conv1D(64, kernel_size=3, padding='same', activation='relu')(decoder_cnn8)\n","        decoder_cnn10 = Conv1D(32, kernel_size=3, padding='same', activation='relu')(decoder_cnn9)\n","        decoder_dense = Dense(self.max_vocab_fr_len + 1, activation='softmax')\n","        decoder_outputs = decoder_dense(decoder_cnn10)\n","        # Add to a model\n","        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","        # Compile the model\n","        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model\n"],"metadata":{"id":"tsqRJpFfsHHM","executionInfo":{"status":"ok","timestamp":1704548274257,"user_tz":-60,"elapsed":286,"user":{"displayName":"Bastian Schäfer","userId":"12245161686255893030"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"20DzbRcForv1"},"source":["## Main"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tn-PY2Aeoo81","executionInfo":{"status":"ok","timestamp":1704550487009,"user_tz":-60,"elapsed":1686545,"user":{"displayName":"Bastian Schäfer","userId":"12245161686255893030"}},"outputId":"901a802a-bcae-439c-85d9-0242c56c2045"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n","CNN_Basic\n","Epoch 1/100\n","202/202 [==============================] - ETA: 0s - loss: 2.0445 - accuracy: 0.8183\n","Epoch 1: val_accuracy improved from -inf to 0.82222, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Basic.best.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r202/202 [==============================] - 32s 147ms/step - loss: 2.0445 - accuracy: 0.8183 - val_loss: 1.8406 - val_accuracy: 0.8222 - epoch_duration: 31.6282 - total_time: 31.6926\n","Epoch 2/100\n","202/202 [==============================] - ETA: 0s - loss: 1.8247 - accuracy: 0.8230\n","Epoch 2: val_accuracy improved from 0.82222 to 0.82373, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Basic.best.h5\n","202/202 [==============================] - 24s 120ms/step - loss: 1.8247 - accuracy: 0.8230 - val_loss: 1.8358 - val_accuracy: 0.8237 - epoch_duration: 24.2981 - total_time: 56.0194\n","Epoch 3/100\n","202/202 [==============================] - ETA: 0s - loss: 1.8152 - accuracy: 0.8237\n","Epoch 3: val_accuracy did not improve from 0.82373\n","202/202 [==============================] - 22s 107ms/step - loss: 1.8152 - accuracy: 0.8237 - val_loss: 1.8421 - val_accuracy: 0.8224 - epoch_duration: 21.6632 - total_time: 77.6930\n","Epoch 4/100\n","202/202 [==============================] - ETA: 0s - loss: 1.8126 - accuracy: 0.8237\n","Epoch 4: val_accuracy improved from 0.82373 to 0.82381, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Basic.best.h5\n","202/202 [==============================] - 23s 112ms/step - loss: 1.8126 - accuracy: 0.8237 - val_loss: 1.8408 - val_accuracy: 0.8238 - epoch_duration: 22.5135 - total_time: 100.2118\n","Epoch 5/100\n","202/202 [==============================] - ETA: 0s - loss: 1.8078 - accuracy: 0.8238\n","Epoch 5: val_accuracy did not improve from 0.82381\n","202/202 [==============================] - 21s 105ms/step - loss: 1.8078 - accuracy: 0.8238 - val_loss: 1.8326 - val_accuracy: 0.8236 - epoch_duration: 21.2296 - total_time: 121.4535\n","Epoch 6/100\n","202/202 [==============================] - ETA: 0s - loss: 1.7996 - accuracy: 0.8244\n","Epoch 6: val_accuracy did not improve from 0.82381\n","202/202 [==============================] - 24s 119ms/step - loss: 1.7996 - accuracy: 0.8244 - val_loss: 1.8404 - val_accuracy: 0.8229 - epoch_duration: 24.0690 - total_time: 145.5291\n","Epoch 7/100\n","202/202 [==============================] - ETA: 0s - loss: 1.7927 - accuracy: 0.8243\n","Epoch 7: val_accuracy did not improve from 0.82381\n","202/202 [==============================] - 21s 103ms/step - loss: 1.7927 - accuracy: 0.8243 - val_loss: 1.8407 - val_accuracy: 0.8228 - epoch_duration: 20.8718 - total_time: 166.4068\n","Epoch 8/100\n","202/202 [==============================] - ETA: 0s - loss: 1.7981 - accuracy: 0.8239\n","Epoch 8: val_accuracy did not improve from 0.82381\n","202/202 [==============================] - 21s 105ms/step - loss: 1.7981 - accuracy: 0.8239 - val_loss: 1.8616 - val_accuracy: 0.8208 - epoch_duration: 21.2521 - total_time: 187.6648\n","Epoch 9/100\n","202/202 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.8242\n","Epoch 9: val_accuracy did not improve from 0.82381\n","202/202 [==============================] - 21s 102ms/step - loss: 1.7903 - accuracy: 0.8242 - val_loss: 1.8612 - val_accuracy: 0.8225 - epoch_duration: 20.6819 - total_time: 208.3543\n","Epoch 9: early stopping\n","1/1 [==============================] - 1s 541ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","CNN_Auto_Bigger\n","Epoch 1/100\n","162/162 [==============================] - ETA: 0s - loss: 2.0214 - accuracy: 0.8086\n","Epoch 1: val_accuracy improved from -inf to 0.83113, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 37s 194ms/step - loss: 2.0214 - accuracy: 0.8086 - val_loss: 1.3021 - val_accuracy: 0.8311 - epoch_duration: 36.5015 - total_time: 36.8825\n","Epoch 2/100\n","162/162 [==============================] - ETA: 0s - loss: 1.2530 - accuracy: 0.8310\n","Epoch 2: val_accuracy improved from 0.83113 to 0.84532, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 23s 139ms/step - loss: 1.2530 - accuracy: 0.8310 - val_loss: 1.1536 - val_accuracy: 0.8453 - epoch_duration: 22.5120 - total_time: 59.4360\n","Epoch 3/100\n","162/162 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.8519\n","Epoch 3: val_accuracy improved from 0.84532 to 0.87278, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 20s 122ms/step - loss: 1.0021 - accuracy: 0.8519 - val_loss: 0.9334 - val_accuracy: 0.8728 - epoch_duration: 19.6621 - total_time: 79.1057\n","Epoch 4/100\n","162/162 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.8804\n","Epoch 4: val_accuracy improved from 0.87278 to 0.89318, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 18s 113ms/step - loss: 0.8042 - accuracy: 0.8804 - val_loss: 0.8496 - val_accuracy: 0.8932 - epoch_duration: 18.2553 - total_time: 97.3693\n","Epoch 5/100\n","162/162 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.8938\n","Epoch 5: val_accuracy improved from 0.89318 to 0.90129, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 18s 109ms/step - loss: 0.7061 - accuracy: 0.8938 - val_loss: 0.8228 - val_accuracy: 0.9013 - epoch_duration: 17.5729 - total_time: 114.9474\n","Epoch 6/100\n","162/162 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.9019\n","Epoch 6: val_accuracy did not improve from 0.90129\n","162/162 [==============================] - 17s 103ms/step - loss: 0.6379 - accuracy: 0.9019 - val_loss: 0.8356 - val_accuracy: 0.8997 - epoch_duration: 16.8190 - total_time: 131.7772\n","Epoch 7/100\n","162/162 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.9062\n","Epoch 7: val_accuracy improved from 0.90129 to 0.91079, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 105ms/step - loss: 0.5938 - accuracy: 0.9062 - val_loss: 0.8300 - val_accuracy: 0.9108 - epoch_duration: 16.9949 - total_time: 148.7789\n","Epoch 8/100\n","162/162 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.9054\n","Epoch 8: val_accuracy improved from 0.91079 to 0.91375, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 18s 111ms/step - loss: 0.5836 - accuracy: 0.9054 - val_loss: 0.8139 - val_accuracy: 0.9137 - epoch_duration: 17.9908 - total_time: 166.7852\n","Epoch 9/100\n","162/162 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.9128\n","Epoch 9: val_accuracy did not improve from 0.91375\n","162/162 [==============================] - 16s 101ms/step - loss: 0.5297 - accuracy: 0.9128 - val_loss: 0.8556 - val_accuracy: 0.9137 - epoch_duration: 16.3878 - total_time: 183.1815\n","Epoch 10/100\n","162/162 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.9134\n","Epoch 10: val_accuracy did not improve from 0.91375\n","162/162 [==============================] - 16s 99ms/step - loss: 0.5135 - accuracy: 0.9134 - val_loss: 0.9468 - val_accuracy: 0.9098 - epoch_duration: 16.0580 - total_time: 199.2481\n","Epoch 11/100\n","162/162 [==============================] - ETA: 0s - loss: 0.4956 - accuracy: 0.9148\n","Epoch 11: val_accuracy improved from 0.91375 to 0.91673, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 104ms/step - loss: 0.4956 - accuracy: 0.9148 - val_loss: 0.9325 - val_accuracy: 0.9167 - epoch_duration: 16.8419 - total_time: 216.0972\n","Epoch 12/100\n","162/162 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.9139\n","Epoch 12: val_accuracy did not improve from 0.91673\n","162/162 [==============================] - 16s 101ms/step - loss: 0.4889 - accuracy: 0.9139 - val_loss: 0.9859 - val_accuracy: 0.9099 - epoch_duration: 16.3248 - total_time: 232.4328\n","Epoch 13/100\n","162/162 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.9203\n","Epoch 13: val_accuracy improved from 0.91673 to 0.92049, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 106ms/step - loss: 0.4526 - accuracy: 0.9203 - val_loss: 1.0284 - val_accuracy: 0.9205 - epoch_duration: 17.2080 - total_time: 249.6462\n","Epoch 14/100\n","162/162 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.9226\n","Epoch 14: val_accuracy improved from 0.92049 to 0.92188, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 101ms/step - loss: 0.4332 - accuracy: 0.9226 - val_loss: 1.0332 - val_accuracy: 0.9219 - epoch_duration: 16.3914 - total_time: 266.0493\n","Epoch 15/100\n","162/162 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.9244\n","Epoch 15: val_accuracy did not improve from 0.92188\n","162/162 [==============================] - 16s 96ms/step - loss: 0.4159 - accuracy: 0.9244 - val_loss: 1.0233 - val_accuracy: 0.9188 - epoch_duration: 15.6017 - total_time: 281.6590\n","Epoch 16/100\n","162/162 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.9270\n","Epoch 16: val_accuracy improved from 0.92188 to 0.92490, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 106ms/step - loss: 0.3955 - accuracy: 0.9270 - val_loss: 1.0938 - val_accuracy: 0.9249 - epoch_duration: 17.1717 - total_time: 298.8395\n","Epoch 17/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.4250 - accuracy: 0.9219\n","Epoch 17: val_accuracy improved from 0.92490 to 0.92827, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 103ms/step - loss: 0.4249 - accuracy: 0.9220 - val_loss: 1.0664 - val_accuracy: 0.9283 - epoch_duration: 16.5868 - total_time: 315.4385\n","Epoch 18/100\n","162/162 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.9330\n","Epoch 18: val_accuracy improved from 0.92827 to 0.92920, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 103ms/step - loss: 0.3573 - accuracy: 0.9330 - val_loss: 1.1020 - val_accuracy: 0.9292 - epoch_duration: 16.6980 - total_time: 332.1451\n","Epoch 19/100\n","162/162 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.9350\n","Epoch 19: val_accuracy improved from 0.92920 to 0.93077, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 106ms/step - loss: 0.3428 - accuracy: 0.9350 - val_loss: 1.1348 - val_accuracy: 0.9308 - epoch_duration: 17.2009 - total_time: 349.3577\n","Epoch 20/100\n","162/162 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.9370\n","Epoch 20: val_accuracy improved from 0.93077 to 0.93280, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 103ms/step - loss: 0.3286 - accuracy: 0.9370 - val_loss: 1.1716 - val_accuracy: 0.9328 - epoch_duration: 16.5960 - total_time: 365.9778\n","Epoch 21/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.3169 - accuracy: 0.9382\n","Epoch 21: val_accuracy did not improve from 0.93280\n","162/162 [==============================] - 16s 97ms/step - loss: 0.3169 - accuracy: 0.9382 - val_loss: 1.2559 - val_accuracy: 0.9321 - epoch_duration: 15.7671 - total_time: 381.7507\n","Epoch 22/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.3108 - accuracy: 0.9383\n","Epoch 22: val_accuracy improved from 0.93280 to 0.93426, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 104ms/step - loss: 0.3109 - accuracy: 0.9382 - val_loss: 1.2151 - val_accuracy: 0.9343 - epoch_duration: 16.8970 - total_time: 398.6528\n","Epoch 23/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.2975 - accuracy: 0.9405\n","Epoch 23: val_accuracy improved from 0.93426 to 0.93602, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 100ms/step - loss: 0.2974 - accuracy: 0.9405 - val_loss: 1.3516 - val_accuracy: 0.9360 - epoch_duration: 16.2328 - total_time: 414.8910\n","Epoch 24/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.9431\n","Epoch 24: val_accuracy did not improve from 0.93602\n","162/162 [==============================] - 16s 96ms/step - loss: 0.2842 - accuracy: 0.9431 - val_loss: 1.3092 - val_accuracy: 0.9350 - epoch_duration: 15.5791 - total_time: 430.4802\n","Epoch 25/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.3038 - accuracy: 0.9383\n","Epoch 25: val_accuracy improved from 0.93602 to 0.93820, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 101ms/step - loss: 0.3037 - accuracy: 0.9384 - val_loss: 1.3222 - val_accuracy: 0.9382 - epoch_duration: 16.2821 - total_time: 446.7691\n","Epoch 26/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9472\n","Epoch 26: val_accuracy did not improve from 0.93820\n","162/162 [==============================] - 16s 97ms/step - loss: 0.2607 - accuracy: 0.9472 - val_loss: 1.2882 - val_accuracy: 0.9370 - epoch_duration: 15.7219 - total_time: 462.5043\n","Epoch 27/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9464\n","Epoch 27: val_accuracy did not improve from 0.93820\n","162/162 [==============================] - 16s 97ms/step - loss: 0.2603 - accuracy: 0.9464 - val_loss: 1.3971 - val_accuracy: 0.9361 - epoch_duration: 15.6451 - total_time: 478.1544\n","Epoch 28/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9483\n","Epoch 28: val_accuracy improved from 0.93820 to 0.93955, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 106ms/step - loss: 0.2503 - accuracy: 0.9483 - val_loss: 1.5066 - val_accuracy: 0.9396 - epoch_duration: 17.1501 - total_time: 495.3090\n","Epoch 29/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.9497\n","Epoch 29: val_accuracy improved from 0.93955 to 0.94013, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 101ms/step - loss: 0.2420 - accuracy: 0.9497 - val_loss: 1.4130 - val_accuracy: 0.9401 - epoch_duration: 16.2699 - total_time: 511.5864\n","Epoch 30/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.9487\n","Epoch 30: val_accuracy did not improve from 0.94013\n","162/162 [==============================] - 15s 95ms/step - loss: 0.2451 - accuracy: 0.9487 - val_loss: 1.3652 - val_accuracy: 0.9320 - epoch_duration: 15.4469 - total_time: 527.0385\n","Epoch 31/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9516\n","Epoch 31: val_accuracy improved from 0.94013 to 0.94380, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 100ms/step - loss: 0.2306 - accuracy: 0.9516 - val_loss: 1.4547 - val_accuracy: 0.9438 - epoch_duration: 16.1894 - total_time: 543.2353\n","Epoch 32/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.2123 - accuracy: 0.9558\n","Epoch 32: val_accuracy improved from 0.94380 to 0.94394, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 99ms/step - loss: 0.2122 - accuracy: 0.9558 - val_loss: 1.6062 - val_accuracy: 0.9439 - epoch_duration: 16.0350 - total_time: 559.2810\n","Epoch 33/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.9559\n","Epoch 33: val_accuracy improved from 0.94394 to 0.94610, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 103ms/step - loss: 0.2091 - accuracy: 0.9559 - val_loss: 1.4962 - val_accuracy: 0.9461 - epoch_duration: 16.6150 - total_time: 575.9072\n","Epoch 34/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.9446\n","Epoch 34: val_accuracy did not improve from 0.94610\n","162/162 [==============================] - 16s 96ms/step - loss: 0.2768 - accuracy: 0.9446 - val_loss: 1.4755 - val_accuracy: 0.9457 - epoch_duration: 15.5541 - total_time: 591.4684\n","Epoch 35/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9588\n","Epoch 35: val_accuracy improved from 0.94610 to 0.94683, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 101ms/step - loss: 0.1957 - accuracy: 0.9588 - val_loss: 1.5824 - val_accuracy: 0.9468 - epoch_duration: 16.2597 - total_time: 607.7341\n","Epoch 36/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.9594\n","Epoch 36: val_accuracy did not improve from 0.94683\n","162/162 [==============================] - 16s 102ms/step - loss: 0.1909 - accuracy: 0.9594 - val_loss: 1.6173 - val_accuracy: 0.9463 - epoch_duration: 16.4407 - total_time: 624.1890\n","Epoch 37/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9600\n","Epoch 37: val_accuracy improved from 0.94683 to 0.94866, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 17s 104ms/step - loss: 0.1870 - accuracy: 0.9600 - val_loss: 1.6217 - val_accuracy: 0.9487 - epoch_duration: 16.8779 - total_time: 641.0724\n","Epoch 38/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9617\n","Epoch 38: val_accuracy did not improve from 0.94866\n","162/162 [==============================] - 15s 94ms/step - loss: 0.1799 - accuracy: 0.9617 - val_loss: 1.5806 - val_accuracy: 0.9474 - epoch_duration: 15.2274 - total_time: 656.3054\n","Epoch 39/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9618\n","Epoch 39: val_accuracy did not improve from 0.94866\n","162/162 [==============================] - 16s 100ms/step - loss: 0.1769 - accuracy: 0.9618 - val_loss: 1.5774 - val_accuracy: 0.9476 - epoch_duration: 16.2298 - total_time: 672.5413\n","Epoch 40/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9605\n","Epoch 40: val_accuracy did not improve from 0.94866\n","162/162 [==============================] - 15s 95ms/step - loss: 0.1800 - accuracy: 0.9605 - val_loss: 1.5185 - val_accuracy: 0.9448 - epoch_duration: 15.3923 - total_time: 687.9387\n","Epoch 41/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9620\n","Epoch 41: val_accuracy improved from 0.94866 to 0.94911, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 101ms/step - loss: 0.1744 - accuracy: 0.9620 - val_loss: 1.6807 - val_accuracy: 0.9491 - epoch_duration: 16.2676 - total_time: 704.2143\n","Epoch 42/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9635\n","Epoch 42: val_accuracy did not improve from 0.94911\n","162/162 [==============================] - 15s 94ms/step - loss: 0.1679 - accuracy: 0.9635 - val_loss: 1.5417 - val_accuracy: 0.9486 - epoch_duration: 15.2489 - total_time: 719.4689\n","Epoch 43/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9646\n","Epoch 43: val_accuracy did not improve from 0.94911\n","162/162 [==============================] - 15s 94ms/step - loss: 0.1626 - accuracy: 0.9645 - val_loss: 1.6992 - val_accuracy: 0.9437 - epoch_duration: 15.1976 - total_time: 734.6720\n","Epoch 44/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9629\n","Epoch 44: val_accuracy improved from 0.94911 to 0.94917, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 100ms/step - loss: 0.1679 - accuracy: 0.9629 - val_loss: 1.6591 - val_accuracy: 0.9492 - epoch_duration: 16.1431 - total_time: 750.8205\n","Epoch 45/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9665\n","Epoch 45: val_accuracy improved from 0.94917 to 0.94998, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 18s 109ms/step - loss: 0.1537 - accuracy: 0.9665 - val_loss: 1.6738 - val_accuracy: 0.9500 - epoch_duration: 17.6037 - total_time: 768.4415\n","Epoch 46/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9662\n","Epoch 46: val_accuracy did not improve from 0.94998\n","162/162 [==============================] - 16s 97ms/step - loss: 0.1534 - accuracy: 0.9662 - val_loss: 1.7091 - val_accuracy: 0.9491 - epoch_duration: 15.7697 - total_time: 784.2285\n","Epoch 47/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9630\n","Epoch 47: val_accuracy did not improve from 0.94998\n","162/162 [==============================] - 15s 95ms/step - loss: 0.1639 - accuracy: 0.9630 - val_loss: 1.5677 - val_accuracy: 0.9495 - epoch_duration: 15.4082 - total_time: 799.6447\n","Epoch 48/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9665\n","Epoch 48: val_accuracy improved from 0.94998 to 0.95246, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Bigger.best.h5\n","162/162 [==============================] - 16s 100ms/step - loss: 0.1509 - accuracy: 0.9665 - val_loss: 1.5823 - val_accuracy: 0.9525 - epoch_duration: 16.1915 - total_time: 815.8428\n","Epoch 49/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9682\n","Epoch 49: val_accuracy did not improve from 0.95246\n","162/162 [==============================] - 15s 95ms/step - loss: 0.1439 - accuracy: 0.9682 - val_loss: 1.6287 - val_accuracy: 0.9521 - epoch_duration: 15.3564 - total_time: 831.2053\n","Epoch 50/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9689\n","Epoch 50: val_accuracy did not improve from 0.95246\n","162/162 [==============================] - 15s 95ms/step - loss: 0.1405 - accuracy: 0.9689 - val_loss: 1.6558 - val_accuracy: 0.9510 - epoch_duration: 15.3794 - total_time: 846.5905\n","Epoch 51/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9675\n","Epoch 51: val_accuracy did not improve from 0.95246\n","162/162 [==============================] - 15s 96ms/step - loss: 0.1461 - accuracy: 0.9675 - val_loss: 1.6683 - val_accuracy: 0.9520 - epoch_duration: 15.4856 - total_time: 862.0820\n","Epoch 52/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1393 - accuracy: 0.9688\n","Epoch 52: val_accuracy did not improve from 0.95246\n","162/162 [==============================] - 15s 94ms/step - loss: 0.1393 - accuracy: 0.9688 - val_loss: 1.6287 - val_accuracy: 0.9518 - epoch_duration: 15.1854 - total_time: 877.2749\n","Epoch 53/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9695\n","Epoch 53: val_accuracy did not improve from 0.95246\n","162/162 [==============================] - 15s 95ms/step - loss: 0.1376 - accuracy: 0.9695 - val_loss: 1.5896 - val_accuracy: 0.9511 - epoch_duration: 15.3829 - total_time: 892.6659\n","Epoch 53: early stopping\n","1/1 [==============================] - 0s 411ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","CNN_Auto_Basic\n","Epoch 1/100\n","162/162 [==============================] - ETA: 0s - loss: 2.8461 - accuracy: 0.8080\n","Epoch 1: val_accuracy improved from -inf to 0.83080, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 25s 141ms/step - loss: 2.8461 - accuracy: 0.8080 - val_loss: 1.3056 - val_accuracy: 0.8308 - epoch_duration: 25.3389 - total_time: 25.7968\n","Epoch 2/100\n","162/162 [==============================] - ETA: 0s - loss: 1.2236 - accuracy: 0.8302\n","Epoch 2: val_accuracy improved from 0.83080 to 0.84314, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 16s 101ms/step - loss: 1.2236 - accuracy: 0.8302 - val_loss: 1.0802 - val_accuracy: 0.8431 - epoch_duration: 16.3718 - total_time: 42.1887\n","Epoch 3/100\n","162/162 [==============================] - ETA: 0s - loss: 1.0035 - accuracy: 0.8504\n","Epoch 3: val_accuracy improved from 0.84314 to 0.87331, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 15s 93ms/step - loss: 1.0035 - accuracy: 0.8504 - val_loss: 0.9359 - val_accuracy: 0.8733 - epoch_duration: 15.0490 - total_time: 57.2429\n","Epoch 4/100\n","162/162 [==============================] - ETA: 0s - loss: 0.7768 - accuracy: 0.8872\n","Epoch 4: val_accuracy improved from 0.87331 to 0.90417, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 14s 85ms/step - loss: 0.7768 - accuracy: 0.8872 - val_loss: 0.8010 - val_accuracy: 0.9042 - epoch_duration: 13.6810 - total_time: 70.9289\n","Epoch 5/100\n","162/162 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.9084\n","Epoch 5: val_accuracy improved from 0.90417 to 0.91688, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 83ms/step - loss: 0.6211 - accuracy: 0.9084 - val_loss: 0.7696 - val_accuracy: 0.9169 - epoch_duration: 13.4549 - total_time: 84.3893\n","Epoch 6/100\n","162/162 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.9206\n","Epoch 6: val_accuracy improved from 0.91688 to 0.92497, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 80ms/step - loss: 0.5290 - accuracy: 0.9206 - val_loss: 0.7654 - val_accuracy: 0.9250 - epoch_duration: 12.9924 - total_time: 97.3889\n","Epoch 7/100\n","162/162 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.9298\n","Epoch 7: val_accuracy improved from 0.92497 to 0.93219, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 79ms/step - loss: 0.4601 - accuracy: 0.9298 - val_loss: 0.7824 - val_accuracy: 0.9322 - epoch_duration: 12.7166 - total_time: 110.1150\n","Epoch 8/100\n","162/162 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.9381\n","Epoch 8: val_accuracy improved from 0.93219 to 0.93787, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 81ms/step - loss: 0.4005 - accuracy: 0.9381 - val_loss: 0.8053 - val_accuracy: 0.9379 - epoch_duration: 13.0468 - total_time: 123.1672\n","Epoch 9/100\n","162/162 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.9440\n","Epoch 9: val_accuracy improved from 0.93787 to 0.94130, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 78ms/step - loss: 0.3532 - accuracy: 0.9440 - val_loss: 0.8292 - val_accuracy: 0.9413 - epoch_duration: 12.6725 - total_time: 135.8487\n","Epoch 10/100\n","162/162 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.9481\n","Epoch 10: val_accuracy improved from 0.94130 to 0.94301, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 82ms/step - loss: 0.3177 - accuracy: 0.9481 - val_loss: 0.8868 - val_accuracy: 0.9430 - epoch_duration: 13.2841 - total_time: 149.1406\n","Epoch 11/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.9508\n","Epoch 11: val_accuracy improved from 0.94301 to 0.94463, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 82ms/step - loss: 0.2904 - accuracy: 0.9508 - val_loss: 0.9429 - val_accuracy: 0.9446 - epoch_duration: 13.3000 - total_time: 162.4501\n","Epoch 12/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.9541\n","Epoch 12: val_accuracy improved from 0.94463 to 0.94672, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 81ms/step - loss: 0.2645 - accuracy: 0.9541 - val_loss: 0.9749 - val_accuracy: 0.9467 - epoch_duration: 13.1154 - total_time: 175.5747\n","Epoch 13/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9562\n","Epoch 13: val_accuracy improved from 0.94672 to 0.94720, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 12s 73ms/step - loss: 0.2449 - accuracy: 0.9562 - val_loss: 1.0174 - val_accuracy: 0.9472 - epoch_duration: 11.8251 - total_time: 187.4279\n","Epoch 14/100\n","162/162 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9579\n","Epoch 14: val_accuracy improved from 0.94720 to 0.94804, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 78ms/step - loss: 0.2278 - accuracy: 0.9579 - val_loss: 1.0761 - val_accuracy: 0.9480 - epoch_duration: 12.5711 - total_time: 200.0088\n","Epoch 15/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9595\n","Epoch 15: val_accuracy improved from 0.94804 to 0.94880, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 82ms/step - loss: 0.2124 - accuracy: 0.9595 - val_loss: 1.1038 - val_accuracy: 0.9488 - epoch_duration: 13.2501 - total_time: 213.2646\n","Epoch 16/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.9617\n","Epoch 16: val_accuracy improved from 0.94880 to 0.94895, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 12s 74ms/step - loss: 0.1958 - accuracy: 0.9617 - val_loss: 1.2050 - val_accuracy: 0.9489 - epoch_duration: 12.0106 - total_time: 225.2851\n","Epoch 17/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9634\n","Epoch 17: val_accuracy did not improve from 0.94895\n","162/162 [==============================] - 13s 79ms/step - loss: 0.1822 - accuracy: 0.9634 - val_loss: 1.1935 - val_accuracy: 0.9487 - epoch_duration: 12.7373 - total_time: 238.0267\n","Epoch 18/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9650\n","Epoch 18: val_accuracy improved from 0.94895 to 0.94976, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 82ms/step - loss: 0.1697 - accuracy: 0.9650 - val_loss: 1.2938 - val_accuracy: 0.9498 - epoch_duration: 13.3370 - total_time: 251.3696\n","Epoch 19/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9662\n","Epoch 19: val_accuracy did not improve from 0.94976\n","162/162 [==============================] - 13s 78ms/step - loss: 0.1591 - accuracy: 0.9662 - val_loss: 1.3188 - val_accuracy: 0.9492 - epoch_duration: 12.6794 - total_time: 264.0553\n","Epoch 20/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9669\n","Epoch 20: val_accuracy did not improve from 0.94976\n","162/162 [==============================] - 12s 72ms/step - loss: 0.1518 - accuracy: 0.9669 - val_loss: 1.4133 - val_accuracy: 0.9493 - epoch_duration: 11.6595 - total_time: 275.7200\n","Epoch 21/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1438 - accuracy: 0.9682\n","Epoch 21: val_accuracy improved from 0.94976 to 0.95212, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 80ms/step - loss: 0.1438 - accuracy: 0.9681 - val_loss: 1.4174 - val_accuracy: 0.9521 - epoch_duration: 13.0057 - total_time: 288.7309\n","Epoch 22/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9718\n","Epoch 22: val_accuracy improved from 0.95212 to 0.95234, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 12s 75ms/step - loss: 0.1249 - accuracy: 0.9718 - val_loss: 1.4950 - val_accuracy: 0.9523 - epoch_duration: 12.0640 - total_time: 300.7998\n","Epoch 23/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9732\n","Epoch 23: val_accuracy improved from 0.95234 to 0.95244, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 12s 76ms/step - loss: 0.1164 - accuracy: 0.9732 - val_loss: 1.4939 - val_accuracy: 0.9524 - epoch_duration: 12.3454 - total_time: 313.1510\n","Epoch 24/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9729\n","Epoch 24: val_accuracy did not improve from 0.95244\n","162/162 [==============================] - 12s 77ms/step - loss: 0.1159 - accuracy: 0.9729 - val_loss: 1.5471 - val_accuracy: 0.9519 - epoch_duration: 12.4847 - total_time: 325.6410\n","Epoch 25/100\n","162/162 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9745\n","Epoch 25: val_accuracy improved from 0.95244 to 0.95308, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 78ms/step - loss: 0.1060 - accuracy: 0.9745 - val_loss: 1.5908 - val_accuracy: 0.9531 - epoch_duration: 12.5649 - total_time: 338.2116\n","Epoch 26/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9761\n","Epoch 26: val_accuracy did not improve from 0.95308\n","162/162 [==============================] - 12s 72ms/step - loss: 0.0987 - accuracy: 0.9761 - val_loss: 1.6155 - val_accuracy: 0.9522 - epoch_duration: 11.5876 - total_time: 349.8140\n","Epoch 27/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0950 - accuracy: 0.9767\n","Epoch 27: val_accuracy did not improve from 0.95308\n","162/162 [==============================] - 12s 76ms/step - loss: 0.0950 - accuracy: 0.9767 - val_loss: 1.6541 - val_accuracy: 0.9522 - epoch_duration: 12.2600 - total_time: 362.0805\n","Epoch 28/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 0.9788\n","Epoch 28: val_accuracy improved from 0.95308 to 0.95329, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 12s 75ms/step - loss: 0.0846 - accuracy: 0.9788 - val_loss: 1.7635 - val_accuracy: 0.9533 - epoch_duration: 12.1253 - total_time: 374.2112\n","Epoch 29/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9807\n","Epoch 29: val_accuracy improved from 0.95329 to 0.95389, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 78ms/step - loss: 0.0768 - accuracy: 0.9807 - val_loss: 1.7344 - val_accuracy: 0.9539 - epoch_duration: 12.6483 - total_time: 386.8668\n","Epoch 30/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 0.9810\n","Epoch 30: val_accuracy did not improve from 0.95389\n","162/162 [==============================] - 13s 77ms/step - loss: 0.0760 - accuracy: 0.9809 - val_loss: 1.8300 - val_accuracy: 0.9531 - epoch_duration: 12.5047 - total_time: 399.3771\n","Epoch 31/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9817\n","Epoch 31: val_accuracy did not improve from 0.95389\n","162/162 [==============================] - 12s 76ms/step - loss: 0.0716 - accuracy: 0.9817 - val_loss: 1.8083 - val_accuracy: 0.9527 - epoch_duration: 12.3495 - total_time: 411.7343\n","Epoch 32/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9822\n","Epoch 32: val_accuracy did not improve from 0.95389\n","162/162 [==============================] - 12s 73ms/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 1.8335 - val_accuracy: 0.9535 - epoch_duration: 11.7474 - total_time: 423.4879\n","Epoch 33/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9831\n","Epoch 33: val_accuracy did not improve from 0.95389\n","162/162 [==============================] - 12s 72ms/step - loss: 0.0655 - accuracy: 0.9831 - val_loss: 1.8728 - val_accuracy: 0.9536 - epoch_duration: 11.6936 - total_time: 435.1885\n","Epoch 34/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9842\n","Epoch 34: val_accuracy improved from 0.95389 to 0.95434, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 80ms/step - loss: 0.0610 - accuracy: 0.9842 - val_loss: 1.9356 - val_accuracy: 0.9543 - epoch_duration: 12.9891 - total_time: 448.1826\n","Epoch 35/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9858\n","Epoch 35: val_accuracy did not improve from 0.95434\n","162/162 [==============================] - 12s 71ms/step - loss: 0.0540 - accuracy: 0.9858 - val_loss: 1.9137 - val_accuracy: 0.9541 - epoch_duration: 11.5296 - total_time: 459.7387\n","Epoch 36/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9873\n","Epoch 36: val_accuracy did not improve from 0.95434\n","162/162 [==============================] - 12s 71ms/step - loss: 0.0485 - accuracy: 0.9873 - val_loss: 1.9944 - val_accuracy: 0.9543 - epoch_duration: 11.5541 - total_time: 471.3003\n","Epoch 37/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9862\n","Epoch 37: val_accuracy did not improve from 0.95434\n","162/162 [==============================] - 12s 74ms/step - loss: 0.0523 - accuracy: 0.9862 - val_loss: 2.0180 - val_accuracy: 0.9521 - epoch_duration: 12.0002 - total_time: 483.3060\n","Epoch 38/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9867\n","Epoch 38: val_accuracy did not improve from 0.95434\n","162/162 [==============================] - 12s 76ms/step - loss: 0.0503 - accuracy: 0.9867 - val_loss: 2.0202 - val_accuracy: 0.9536 - epoch_duration: 12.2579 - total_time: 495.5699\n","Epoch 39/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9878\n","Epoch 39: val_accuracy improved from 0.95434 to 0.95470, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 83ms/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 2.0411 - val_accuracy: 0.9547 - epoch_duration: 13.3902 - total_time: 508.9653\n","Epoch 40/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9896\n","Epoch 40: val_accuracy improved from 0.95470 to 0.95553, saving model to drive/My Drive/Colab Notebooks/Université Jean Monet/Deep Learning II/Project/results/weights/weights_CNN_Auto_Basic.best.h5\n","162/162 [==============================] - 13s 79ms/step - loss: 0.0385 - accuracy: 0.9896 - val_loss: 2.0763 - val_accuracy: 0.9555 - epoch_duration: 12.7277 - total_time: 521.7124\n","Epoch 41/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9901\n","Epoch 41: val_accuracy did not improve from 0.95553\n","162/162 [==============================] - 12s 73ms/step - loss: 0.0377 - accuracy: 0.9901 - val_loss: 2.1421 - val_accuracy: 0.9544 - epoch_duration: 11.8189 - total_time: 533.5494\n","Epoch 42/100\n","161/162 [============================>.] - ETA: 0s - loss: 0.0381 - accuracy: 0.9898\n","Epoch 42: val_accuracy did not improve from 0.95553\n","162/162 [==============================] - 12s 71ms/step - loss: 0.0381 - accuracy: 0.9898 - val_loss: 2.1141 - val_accuracy: 0.9540 - epoch_duration: 11.5202 - total_time: 545.0757\n","Epoch 43/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9897\n","Epoch 43: val_accuracy did not improve from 0.95553\n","162/162 [==============================] - 12s 72ms/step - loss: 0.0385 - accuracy: 0.9897 - val_loss: 2.1213 - val_accuracy: 0.9542 - epoch_duration: 11.6800 - total_time: 556.7607\n","Epoch 44/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9898\n","Epoch 44: val_accuracy did not improve from 0.95553\n","162/162 [==============================] - 12s 72ms/step - loss: 0.0379 - accuracy: 0.9898 - val_loss: 2.1401 - val_accuracy: 0.9538 - epoch_duration: 11.6493 - total_time: 568.4185\n","Epoch 45/100\n","162/162 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9905\n","Epoch 45: val_accuracy did not improve from 0.95553\n","162/162 [==============================] - 12s 73ms/step - loss: 0.0351 - accuracy: 0.9905 - val_loss: 2.1140 - val_accuracy: 0.9551 - epoch_duration: 11.7835 - total_time: 580.2096\n","Epoch 45: early stopping\n","1/1 [==============================] - 0s 160ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n"]}],"source":["# --- 1. We import the libraries we need ---\n","import numpy as np\n","import tensorflow as tf\n","import argparse\n","import pandas as pd\n","import time\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, Callback\n","\n","\n","# --- 2. We define testing modules ---\n","\n","def translate_sequence(seq, tokenizer):\n","    \"\"\" Translates a sequence of integers back into text using the tokenizer. \"\"\"\n","    words = [tokenizer.index_word.get(idx, '') for idx in seq]\n","    return ' '.join(words).strip()\n","\n","def predict_and_compare(index, testX, model, tokenizer_en, tokenizer_fr):\n","    \"\"\" Predicts translation for a given index in the test set and compares with the ground truth. \"\"\"\n","    input_seq = testX[index:index+1]\n","    prediction = model.predict(input_seq)\n","\n","    # Converting the prediction to a sequence of integers\n","    predicted_seq = np.argmax(prediction, axis=-1)[0]\n","\n","    # Reverse tokenization (converting sequences back to words)\n","    input_text = translate_sequence(input_seq[0], tokenizer_en)\n","    predicted_text = translate_sequence(predicted_seq, tokenizer_fr)\n","    ground_truth_text = translate_sequence(testY[index].flatten(), tokenizer_fr)\n","\n","    # Return results\n","    return input_text, predicted_text, ground_truth_text\n","\n","def predict_and_compare_auto_en(index, testX, testY, model, tokenizer_en, tokenizer_fr):\n","    \"\"\" Predicts translation for a given index in the test set and compares with the ground truth. \"\"\"\n","    input_seq_X = testX[index:index+1]\n","    input_seq_Y = testY[index:index+1]\n","    prediction = model.predict([input_seq_X, input_seq_Y])\n","\n","    # Converting the prediction to a sequence of integers\n","    predicted_seq = np.argmax(prediction, axis=-1)[0]\n","\n","    # Reverse tokenization (converting sequences back to words)\n","    input_text = translate_sequence(input_seq_X[0], tokenizer_en)\n","    predicted_text = translate_sequence(predicted_seq, tokenizer_fr)\n","    ground_truth_text = translate_sequence(testY[index].flatten(), tokenizer_fr)\n","\n","    # Return results\n","    return input_text, predicted_text, ground_truth_text\n","\n","\n","class TimedCSVLogger(CSVLogger):\n","    def __init__(self, filename, separator=',', append=False):\n","        super().__init__(filename, separator, append)\n","        self.start_time = time.time()\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        self.epoch_start_time = time.time()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        end_time = time.time()\n","        logs['epoch_duration'] = end_time - self.epoch_start_time\n","        logs['total_time'] = end_time - self.start_time\n","        super().on_epoch_end(epoch, logs)\n","\n","# --- 3. We check the gpus available ---\n","\n","if __name__ == '__main__':\n","\n","    gpus = tf.config.experimental.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            # Set TensorFlow to use only one GPU\n","            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n","\n","            # Enable memory growth\n","            tf.config.experimental.set_memory_growth(gpus[0], True)\n","\n","            print(\"Using GPU:\", gpus[0])\n","        except RuntimeError as e:\n","            # Memory growth must be set at program startup\n","            print(\"RuntimeError:\", e)\n","    #else:\n","        #raise SystemError(\"GPU device not found\")\n","\n","    # --- 4. We define global variables ---\n","\n","    EPOCHS = 100\n","    BATCH_SIZE = 32\n","    MAX_VOCAB_SIZE_FR = 20500\n","\n","    # --- 3. We open the data and apply tokenization ---\n","\n","    df = pd.read_csv(path + 'preprocessed_data.csv')\n","\n","    tokenizer_en = Tokenizer()\n","    tokenizer_en.fit_on_texts(df['en_tokens'])\n","    tokenizer_fr = Tokenizer(num_words=MAX_VOCAB_SIZE_FR + 1)\n","    tokenizer_fr.fit_on_texts(df['fr_tokens'])\n","\n","    # Convert text to sequences\n","    sequences_en = tokenizer_en.texts_to_sequences(df['en_tokens'])\n","    sequences_fr = tokenizer_fr.texts_to_sequences(df['fr_tokens'])\n","\n","    # Padding sequences\n","    max_len = max(max(len(s) for s in sequences_en), max(len(s) for s in sequences_fr))\n","    sequences_en = pad_sequences(sequences_en, maxlen=max_len, padding='post')\n","    sequences_fr = pad_sequences(sequences_fr, maxlen=max_len, padding='post')\n","\n","    # Splitting the data\n","    split = int(len(sequences_en) * 0.8)\n","    trainX, testX = sequences_en[:split], sequences_en[split:]\n","    trainY, testY = sequences_fr[:split], sequences_fr[split:]\n","\n","    # Finally, reshape data for feeding into model (French words)\n","    trainY = trainY.reshape(trainY.shape[0], trainY.shape[1], 1)\n","    testY = testY.reshape(testY.shape[0], testY.shape[1], 1)\n","\n","    # --- 4. We load the model ---\n","    method_name = ['CNN_Basic', 'CNN_Auto_Bigger', 'CNN_Auto_Basic' ]  # , 'CNN_ByteNet']\n","    method_instance = [CNN_Basic(tokenizer_en, tokenizer_fr, max_len, MAX_VOCAB_SIZE_FR),\n","                       CNN_Auto_Bigger(tokenizer_en, tokenizer_fr, max_len, MAX_VOCAB_SIZE_FR),\n","                       CNN_Auto_Basic(tokenizer_en, tokenizer_fr, max_len, MAX_VOCAB_SIZE_FR)]  # , CNN_ByteNet(MAX_VOCAB_SIZE_FR)]\n","\n","    # Shared Callbacks\n","    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n","\n","    for i in range(len(method_name)):\n","        print(method_name[i])\n","        current_model = method_instance[i].build_model()\n","\n","        # --- 5. We train the model ---\n","        checkpoint = ModelCheckpoint(path + 'results/weights/weights_' + method_name[i] + '.best.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","        csv_logger = TimedCSVLogger(path + 'results/training_log/training_log_' + method_name[i] + '.csv', append=True)\n","        if method_name[i] == 'CNN_ByteNet':\n","            run_CNN_ByteNet()\n","        elif method_name[i] == 'CNN_Auto_Basic' or method_name[i] == 'CNN_Auto_Bigger':\n","            current_model.fit([trainX, np.squeeze(trainY, axis=-1)], trainY,\n","                              epochs=EPOCHS,\n","                              validation_split=0.2,\n","                              batch_size=BATCH_SIZE,\n","                              callbacks=[checkpoint, csv_logger, early_stopping])\n","        else:\n","            current_model.fit(trainX, trainY,\n","                              epochs=EPOCHS,\n","                              validation_data=(testX, testY),\n","                              batch_size=BATCH_SIZE,\n","                              callbacks=[checkpoint, csv_logger, early_stopping])\n","\n","\n","        # --- 6. We test the model (Change for more meaningful metrics like BLEU) ---\n","\n","        all_predictions = []\n","        for j in range(5):\n","            if method_name[i] == 'CNN_Auto_Basic' or method_name[i] == 'CNN_Auto_Bigger':\n","                input_text, predicted_text, ground_truth_text = predict_and_compare_auto_en(index=j, testX=testX,\n","                                                                                            testY=np.squeeze(testY, axis=-1),\n","                                                                                            model=current_model,\n","                                                                                            tokenizer_en=tokenizer_en,\n","                                                                                            tokenizer_fr=tokenizer_fr)\n","            else:\n","                input_text, predicted_text, ground_truth_text = predict_and_compare(index=j, testX=testX,\n","                                                                                    model=current_model,\n","                                                                                    tokenizer_en=tokenizer_en,\n","                                                                                    tokenizer_fr=tokenizer_fr)\n","            all_predictions.append((input_text, predicted_text, ground_truth_text))\n","\n","        # Writing predictions to a text file\n","        with open(path + 'results/predictions/model_predictions_' + method_name[i] + '.txt', 'w', encoding='utf-8') as file:\n","            for input_text, predicted_text, ground_truth in all_predictions:\n","                file.write(\"Input (English): \" + input_text + \"\\n\")\n","                file.write(\"Predicted (French): \" + predicted_text + \"\\n\")\n","                file.write(\"Ground Truth (French): \" + ground_truth + \"\\n\")\n","                file.write(\"----------\\n\")\n","\n","def sample_top(a=[], top_k=10):\n","    idx = np.argsort(a)[::-1]\n","    idx = idx[:top_k]\n","    probs = a[idx]\n","    probs = probs / np.sum(probs)\n","    choice = np.random.choice(idx, p=probs)\n","    return choice\n","\n","\n","def run_CNN_ByteNet():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--learning_rate', type=float, default=0.001,\n","                        help='Learning Rate')\n","    parser.add_argument('--bucket_quant', type=int, default=50,\n","                        help='Bucket Quant')\n","    parser.add_argument('--beta1', type=float, default=0.5,\n","                        help='Momentum for Adam Update')\n","    parser.add_argument('--resume_model', type=str, default=None,\n","                        help='Pre-Trained Model Path, to resume from')\n","    parser.add_argument('--sample_every', type=int, default=500,\n","                        help='Sample generator output every x steps')\n","    parser.add_argument('--summary_every', type=int, default=50,\n","                        help='Sample generator output every x steps')\n","    parser.add_argument('--top_k', type=int, default=5,\n","                        help='Sample from top k predictions')\n","    args = parser.parse_args()\n","\n","    translator_model = CNN_ByteNet(MAX_VOCAB_SIZE_FR)\n","    translator_model.build_options()\n","\n","    optim = tf.keras.optimizers.Adam(args.learning_rate)\n","\n","    translator_model.build_translator(reuse=True)\n","    translator_model.build_model(MAX_VOCAB_SIZE_FR)\n","    merged_summary = tf.compat.v1.summary.merge_all()\n","\n","    sess = tf.compat.v1.InteractiveSession()\n","    tf.compat.v1.initialize_all_variables().run()\n","    saver = tf.compat.v1.train.Saver()\n","\n","    if args.resume_model:\n","        saver.restore(sess, args.resume_model)\n","\n","    step = 0\n","    for epoch in range(EPOCHS):\n","        batch_no = 0\n","        start = time.process_time()\n","\n","        _, loss, prediction = sess.run(\n","            [optim, translator_model.loss, translator_model.arg_max_prediction],\n","\n","            feed_dict={\n","                translator_model.source_sentence: trainX,\n","                translator_model.target_sentence: trainY,\n","            })\n","        end = time.process_time()\n","\n","        print\n","        \"LOSS: {}\\tEPOCH: {}\\tBATCH_NO: {}\\t STEP:{}\\t total_batches:{}\\t bucket_size:{}\".format(\n","            loss, epoch, batch_no, step)\n","        print\n","        \"TIME FOR BATCH\", end - start\n","\n","        batch_no += 1\n","        step += 1\n","        if step % args.summary_every == 0:\n","            [summary] = sess.run([merged_summary], feed_dict={\n","                translator_model.source_sentence: trainX,\n","                translator_model.target_sentence: trainY,\n","            })\n","            print\n","            \"******\"\n","            print\n","            \"Source \", trainX\n","            print\n","            \"---------\"\n","            print\n","            \"Target \", trainY\n","            print\n","            \"----------\"\n","            print\n","            \"Prediction \", prediction\n","            print\n","            \"******\"\n","\n","        if step % args.sample_every == 0:\n","            log_file = open('translator_sample.txt', 'wb')\n","            generated_target = trainY[:, 0:1]\n","            for col in range(batch_no):\n","                [probs] = sess.run([translator_model.t_probs],\n","                                   feed_dict={\n","                                       translator_model.t_source_sentence: trainX,\n","                                       translator_model.t_target_sentence: generated_target,\n","                                   })\n","\n","                curr_preds = []\n","                for bi in range(probs.shape[0]):\n","                    pred_word = sample_top(probs[bi][-1], top_k=args.top_k)\n","                    curr_preds.append(pred_word)\n","\n","                generated_target = np.insert(generated_target, generated_target.shape[1],\n","                                             curr_preds, axis=1)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNpGbs3FX3q/8kIICZc3Q19"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}