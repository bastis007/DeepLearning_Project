{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KlsWlLqiWih"
   },
   "source": [
    "# Pre-Processing Pipeline\n",
    "\n",
    "**Author:** Felipe Cortes Jaramillo\n",
    "\n",
    "**Description:** Pre-processing pipeline for text translation.\n",
    "\n",
    "**References:** https://github.com/tommytracey/AIND-Capstone/blob/master/machine_translation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KO5vkfQLo4ZD"
   },
   "source": [
    "## Installing Packages and Downloading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xY0tW5-RfibX",
    "outputId": "355c76c2-85b3-41da-a5f5-b40c402dfe63",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:31:56.208312Z",
     "start_time": "2023-12-19T16:31:53.598662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (2.15.0)\r\n",
      "Requirement already satisfied: pandas in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (2.1.3)\r\n",
      "Requirement already satisfied: nltk in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: clean-text in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (0.6.0)\r\n",
      "Requirement already satisfied: tensorflow in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (2.14.0)\r\n",
      "Requirement already satisfied: torchmetrics in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (1.2.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (1.26.2)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (14.0.1)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (0.3.7)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (4.66.1)\r\n",
      "Requirement already satisfied: xxhash in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (3.9.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (0.19.4)\r\n",
      "Requirement already satisfied: packaging in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: click in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from nltk) (2023.10.3)\r\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from clean-text) (1.7.0)\r\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from clean-text) (6.1.3)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (2.0.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (3.10.0)\r\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (4.21.12)\r\n",
      "Requirement already satisfied: setuptools in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (68.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (4.8.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (1.54.3)\r\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (2.14.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (2.14.0)\r\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorflow) (2.14.0)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from torchmetrics) (2.1.2)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from torchmetrics) (0.10.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.12)\r\n",
      "Requirement already satisfied: filelock in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.4)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\r\n",
      "Requirement already satisfied: sympy in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Install Hugging Face Library for Datasets\n",
    "!pip install datasets pandas nltk clean-text tensorflow torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Yi1ZQkSgSF5",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:01.548726Z",
     "start_time": "2023-12-19T16:31:59.267327Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "import nltk\n",
    "from cleantext import clean\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, GRU, LSTM, Bidirectional, Dropout, Input, Dense, Conv1D, MaxPool1D, Conv1DTranspose, SimpleRNN\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from torchmetrics.text import TranslationEditRate\n",
    "from torchmetrics.text.bert import BERTScore\n",
    "from torchmetrics.text.bleu import BLEUScore\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "from torchmetrics.text.wer import WordErrorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:39:02.315102Z",
     "start_time": "2023-12-17T15:39:02.300688Z"
    }
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mSystemError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRuntimeError:\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 16\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mSystemError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU device not found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mSystemError\u001B[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "# Check if TensorFlow is able to detect the GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set TensorFlow to use only one GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Enable memory growth\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set at program startup\n",
    "        print(\"RuntimeError:\", e)\n",
    "else:\n",
    "    raise SystemError(\"GPU device not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oK5js_c4gidk",
    "outputId": "edf107e2-384c-4ce4-a97f-7bffaa9b8ade",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:18.487732Z",
     "start_time": "2023-12-19T16:32:16.133280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  en  \\\n0                                Jamaica: “I am HIV”   \n1  It's widely acknowledged, in the Caribbean and...   \n2  For this woman, however, photographed in the s...   \n3                       As Bacon writes on her blog:   \n4  “When I asked to take her picture, I suggested...   \n\n                                                  fr  \n0                             Jamaïque : J’ai le VIH  \n1  Il est largement reconnu, dans les Caraïbes et...  \n2  Pour cette femme, cependant, photographiée dan...  \n3                    Comme Bacon écrit sur son blog:  \n4  “Quand je lui ai demandé de la prendre en phot...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>fr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jamaica: “I am HIV”</td>\n      <td>Jamaïque : J’ai le VIH</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It's widely acknowledged, in the Caribbean and...</td>\n      <td>Il est largement reconnu, dans les Caraïbes et...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>For this woman, however, photographed in the s...</td>\n      <td>Pour cette femme, cependant, photographiée dan...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>As Bacon writes on her blog:</td>\n      <td>Comme Bacon écrit sur son blog:</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>“When I asked to take her picture, I suggested...</td>\n      <td>“Quand je lui ai demandé de la prendre en phot...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract dataset\n",
    "translation_dataset = load_dataset('Nicolas-BZRD/Parallel_Global_Voices_English_French',\n",
    "                                   split='train').to_pandas()\n",
    "translation_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Q1JjGsN5Ym3P",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:18.492321Z",
     "start_time": "2023-12-19T16:32:18.489272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove line when finishied (OPTIONAL)\n",
    "\n",
    "df = translation_dataset.head(8060)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0A33mW3pEPH"
   },
   "source": [
    "## Data Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1VsvJZgWW9P",
    "outputId": "a1a1828b-79dd-44a3-fbe6-9d3de62d9a9c",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:24.775898Z",
     "start_time": "2023-12-19T16:32:19.375998Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/schaefer.bastian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/var/folders/p9/q_n4s9cj6m15m7f_8tvsd0380000gn/T/ipykernel_25178/1249602603.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['en'] = df['en'].apply(clean_text)\n",
      "/var/folders/p9/q_n4s9cj6m15m7f_8tvsd0380000gn/T/ipykernel_25178/1249602603.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['fr'] = df['fr'].apply(clean_text)\n",
      "/var/folders/p9/q_n4s9cj6m15m7f_8tvsd0380000gn/T/ipykernel_25178/1249602603.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['en_tokens'] = df['en'].apply(word_tokenize)\n",
      "/var/folders/p9/q_n4s9cj6m15m7f_8tvsd0380000gn/T/ipykernel_25178/1249602603.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['fr_tokens'] = df['fr'].apply(word_tokenize)\n",
      "/var/folders/p9/q_n4s9cj6m15m7f_8tvsd0380000gn/T/ipykernel_25178/1249602603.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=['en', 'fr'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# First step - Data Pre-processing\n",
    "\n",
    "# nltk downloads\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define a cleaning function\n",
    "def clean_text(text):\n",
    "    return clean(text,\n",
    "                 fix_unicode=True,               # fix various unicode errors\n",
    "                 to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                 lower=True,                     # lowercase text\n",
    "                 no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "                 no_urls=True,                   # replace all URLs with a special token\n",
    "                 no_emails=True,                 # replace all email addresses with a special token\n",
    "                 no_phone_numbers=True,          # replace all phone numbers with a special token\n",
    "                 no_numbers=False,               # replace all numbers with a special token\n",
    "                 no_digits=False,                # replace all digits with a special token\n",
    "                 no_currency_symbols=True,       # replace all currency symbols with a special token\n",
    "                 no_punct=True,                  # remove punctuations\n",
    "                 replace_with_punct=\"\",          # replace punctuations with this character\n",
    "                 replace_with_url=\"<URL>\",\n",
    "                 replace_with_email=\"<EMAIL>\",\n",
    "                 replace_with_phone_number=\"<PHONE>\",\n",
    "                 replace_with_number=\"<NUMBER>\",\n",
    "                 replace_with_digit=\"<DIGIT>\",\n",
    "                 replace_with_currency_symbol=\"<CUR>\",\n",
    "                 lang=\"en\")\n",
    "\n",
    "# Apply cleaning function to both English and French columns\n",
    "df['en'] = df['en'].apply(clean_text)\n",
    "df['fr'] = df['fr'].apply(clean_text)\n",
    "\n",
    "# Tokenization\n",
    "df['en_tokens'] = df['en'].apply(word_tokenize)\n",
    "df['fr_tokens'] = df['fr'].apply(word_tokenize)\n",
    "\n",
    "# Handling missing data\n",
    "df.dropna(subset=['en', 'fr'], inplace=True)\n",
    "\n",
    "# Save the preprocessed data\n",
    "df.to_csv('preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dknJrE0jY49t",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:25.140898Z",
     "start_time": "2023-12-19T16:32:24.833677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Second step - Data Transformation for Training\n",
    "\n",
    "# Tokenization\n",
    "tokenizer_en = Tokenizer()\n",
    "tokenizer_en.fit_on_texts(df['en_tokens'])\n",
    "tokenizer_fr = Tokenizer()\n",
    "tokenizer_fr.fit_on_texts(df['fr_tokens'])\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences_en = tokenizer_en.texts_to_sequences(df['en_tokens'])\n",
    "sequences_fr = tokenizer_fr.texts_to_sequences(df['fr_tokens'])\n",
    "\n",
    "# Padding sequences\n",
    "max_len = max(max(len(s) for s in sequences_en), max(len(s) for s in sequences_fr))\n",
    "sequences_en = pad_sequences(sequences_en, maxlen=max_len, padding='post')\n",
    "sequences_fr = pad_sequences(sequences_fr, maxlen=max_len, padding='post')\n",
    "\n",
    "# Splitting the data\n",
    "split = int(len(sequences_en) * 0.8)\n",
    "trainX, testX = sequences_en[:split], sequences_en[split:]\n",
    "trainY, testY = sequences_fr[:split], sequences_fr[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kseUIUXIb45Y",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:25.840223Z",
     "start_time": "2023-12-19T16:32:25.832317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Third step - Reshape data for feeding into model (French words)\n",
    "trainY = trainY.reshape(trainY.shape[0], trainY.shape[1], 1)\n",
    "testY = testY.reshape(testY.shape[0], testY.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5ANTSUdAl1_5",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:26.886887Z",
     "start_time": "2023-12-19T16:32:26.882581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<--- Data Preprocessed Summary: --->\n",
      "Max English sentence length: 121\n",
      "Max French sentence length: 121\n",
      "English vocabulary size: 16633\n",
      "French vocabulary size: 20821\n"
     ]
    }
   ],
   "source": [
    "# Fourth Step - Some relevant information after pre-processing and transforming\n",
    "max_english_sequence_length = sequences_en.shape[1]\n",
    "max_french_sequence_length = sequences_fr.shape[1]\n",
    "english_vocab_size = len(tokenizer_en.word_index)\n",
    "french_vocab_size = len(tokenizer_fr.word_index)\n",
    "\n",
    "print('<--- Data Preprocessed Summary: --->')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2QXSWTSi854"
   },
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dQ1U5Y68eWdW",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:29.334283Z",
     "start_time": "2023-12-19T16:32:29.329191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing Module - Models\n",
    "\n",
    "def translate_sequence(seq, tokenizer):\n",
    "    \"\"\" Translates a sequence of integers back into text using the tokenizer. \"\"\"\n",
    "    words = [tokenizer.index_word.get(idx, '') for idx in seq]\n",
    "    return ' '.join(words).strip()\n",
    "\n",
    "def predict_and_compare(index, testX, model, tokenizer_en, tokenizer_fr):\n",
    "    \"\"\" Predicts translation for a given index in the test set and compares with the ground truth. \"\"\"\n",
    "    input_seq = testX[index:index+1]\n",
    "    prediction = model.predict(input_seq)\n",
    "\n",
    "    # Converting the prediction to a sequence of integers\n",
    "    predicted_seq = np.argmax(prediction, axis=-1)[0]\n",
    "\n",
    "    # Reverse tokenization (converting sequences back to words)\n",
    "    input_text = translate_sequence(input_seq[0], tokenizer_en)\n",
    "    predicted_text = translate_sequence(predicted_seq, tokenizer_fr)\n",
    "    ground_truth_text = translate_sequence(testY[index].flatten(), tokenizer_fr)\n",
    "\n",
    "    print(\"Input (English):\", input_text)\n",
    "    print(\"Predicted (French):\", predicted_text)\n",
    "    print(\"Ground Truth (French):\", ground_truth_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IiyExGsibDRF",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:32:30.291110Z",
     "start_time": "2023-12-19T16:32:30.283291Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Section - First Model RNN\n",
    "\n",
    "def simple_rnn(tokenizer_en, tokenizer_fr):\n",
    "\n",
    "  # Define structure of the model\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(input_dim=len(tokenizer_en.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "  model.add(SimpleRNN(64, return_sequences=True))\n",
    "  model.add(Dense(len(tokenizer_fr.word_index) + 1, activation='softmax'))\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w473VlYnb1sd",
    "outputId": "a61bfe6f-7711-4344-f829-d3448e1bc77a",
    "ExecuteTime": {
     "end_time": "2023-12-19T16:55:58.337170Z",
     "start_time": "2023-12-19T16:32:31.431119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "101/101 [==============================] - 157s 2s/step - loss: 5.1574 - accuracy: 0.7945 - val_loss: 1.8007 - val_accuracy: 0.8247\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 171s 2s/step - loss: 1.7456 - accuracy: 0.8250 - val_loss: 1.7698 - val_accuracy: 0.8242\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 129s 1s/step - loss: 1.8292 - accuracy: 0.8207 - val_loss: 1.8502 - val_accuracy: 0.8208\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 127s 1s/step - loss: 1.8495 - accuracy: 0.8191 - val_loss: 1.7379 - val_accuracy: 0.8225\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 128s 1s/step - loss: 1.4717 - accuracy: 0.8252 - val_loss: 1.4379 - val_accuracy: 0.8247\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 147s 1s/step - loss: 1.3644 - accuracy: 0.8256 - val_loss: 1.4164 - val_accuracy: 0.8240\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 146s 1s/step - loss: 1.3428 - accuracy: 0.8270 - val_loss: 1.4144 - val_accuracy: 0.8236\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 135s 1s/step - loss: 1.3307 - accuracy: 0.8278 - val_loss: 1.4124 - val_accuracy: 0.8246\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 132s 1s/step - loss: 1.3208 - accuracy: 0.8283 - val_loss: 1.4126 - val_accuracy: 0.8240\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 135s 1s/step - loss: 1.3102 - accuracy: 0.8288 - val_loss: 1.4134 - val_accuracy: 0.8237\n",
      "CPU times: user 1h 58min 29s, sys: 13min 38s, total: 2h 12min 8s\n",
      "Wall time: 23min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x2ccae6410>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Testing simple RNN\n",
    "\n",
    "simple_rnn_instance = simple_rnn(tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)\n",
    "simple_rnn_instance.fit(trainX, trainY, epochs=10, validation_data=(testX, testY), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "____________________________________________________________"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n",
      "Input (English): do you believe uganda has a free press\n",
      "Predicted (French): de de de de de de de\n",
      "Ground Truth (French): croyezvous que louganda a une presse libre\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input (English): a for the moment the traditional media are basically safe at least until the end of the commonwealth heads of government meeting in november\n",
      "Predicted (French): le de de de de de de de de de de de de de de de de de  de   de de\n",
      "Ground Truth (French): a pour le moment les media traditionnels sont saufs au moins jusqua la fin de la reunion des chefs de gouvernement du commonwealth en novembre\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input (English): but the cracks have already started to appear with upcountry radio stations in places like the toro region in western uganda being harassed for all kinds of things\n",
      "Predicted (French): il la de de de de de de de de de de de de de de de  de   de  de  de de\n",
      "Ground Truth (French): mais les failles ont deja commence a apparaitre les stations de radio en place dans la region de toro dans louest de louganda sont harcelees pour toutes sortes de choses\n"
     ]
    }
   ],
   "source": [
    "# Predicting with simple RNN (First 3 Test Samples)\n",
    "for i in range(3):\n",
    "    predict_and_compare(index=i, testX=testX, model=simple_rnn_instance, tokenizer_en=tokenizer_en, tokenizer_fr=tokenizer_fr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T16:55:58.652504Z",
     "start_time": "2023-12-19T16:55:58.336673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(len(testY))\n",
    "print(index)\n",
    "input_seq = testX[index:index+1]\n",
    "prediction = simple_rnn_instance.predict(input_seq)\n",
    "predicted_seq = np.argmax(prediction, axis=-1)[0]\n",
    "predicted_text = translate_sequence(predicted_seq, tokenizer_fr)\n",
    "ground_truth_text = translate_sequence(testY[index].flatten(), tokenizer_fr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T16:56:03.085029Z",
     "start_time": "2023-12-19T16:56:03.032909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# BLEU\n",
    "bleu = BLEUScore()\n",
    "bleu_score = bleu(predicted_text, ground_truth_text)\n",
    "print(bleu_score.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T16:56:06.341497Z",
     "start_time": "2023-12-19T16:56:06.330777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.216216087341309\n"
     ]
    }
   ],
   "source": [
    "# TER\n",
    "ter = TranslationEditRate()\n",
    "ter_score = ter(predicted_text, ground_truth_text)\n",
    "print(ter_score.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T16:56:07.504155Z",
     "start_time": "2023-12-19T16:56:07.492583Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000149011612\n",
      "0.1111111119389534\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# ROUGE score\n",
    "rouge = ROUGEScore()\n",
    "rouge_score = rouge(predicted_text, ground_truth_text)\n",
    "print(rouge_score['rouge1_fmeasure'].item())\n",
    "print(rouge_score['rouge1_precision'].item())\n",
    "print(rouge_score['rouge2_fmeasure'].item())\n",
    "print(rouge_score['rouge2_precision'].item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T16:56:08.842379Z",
     "start_time": "2023-12-19T16:56:08.832236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# WER\n",
    "wer = WordErrorRate()\n",
    "wer_score = wer(predicted_text, ground_truth_text)\n",
    "print(wer_score.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T16:56:10.090484Z",
     "start_time": "2023-12-19T16:56:10.079551Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schaefer.bastian/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The argument `model_name_or_path` was not specified while it is required when the default `transformers` model is used. It will use the default recommended model - 'roberta-large'.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc9904fcab9e445499030d9ac01e7ba0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript b has size 84 for operand 1 which does not broadcast with previously seen size 27",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m     bert_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmpty prediction, no score\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m----> 6\u001B[0m     bert_score \u001B[38;5;241m=\u001B[39m \u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredicted_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mground_truth_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(bert_score)\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torchmetrics/metric.py:298\u001B[0m, in \u001B[0;36mMetric.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    296\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_full_state_update(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 298\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_reduce_state_update\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torchmetrics/metric.py:368\u001B[0m, in \u001B[0;36mMetric._forward_reduce_state_update\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;66;03m# calculate batch state and compute batch value\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 368\u001B[0m batch_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# reduce batch and global state\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_count \u001B[38;5;241m=\u001B[39m _update_count \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torchmetrics/metric.py:610\u001B[0m, in \u001B[0;36mMetric._wrap_compute.<locals>.wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;66;03m# compute relies on the sync context manager to gather the states across processes and apply reduction\u001B[39;00m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;66;03m# if synchronization happened, the current rank accumulated states will be restored to keep\u001B[39;00m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;66;03m# accumulation going if ``should_unsync=True``,\u001B[39;00m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msync_context(\n\u001B[1;32m    606\u001B[0m     dist_sync_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdist_sync_fn,\n\u001B[1;32m    607\u001B[0m     should_sync\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_to_sync,\n\u001B[1;32m    608\u001B[0m     should_unsync\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_unsync,\n\u001B[1;32m    609\u001B[0m ):\n\u001B[0;32m--> 610\u001B[0m     value \u001B[38;5;241m=\u001B[39m _squeeze_if_scalar(\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    612\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_with_cache:\n\u001B[1;32m    613\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_computed \u001B[38;5;241m=\u001B[39m value\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torchmetrics/text/bert.py:241\u001B[0m, in \u001B[0;36mBERTScore.compute\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    233\u001B[0m preds \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: dim_zero_cat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreds_input_ids),\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: dim_zero_cat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreds_attention_mask),\n\u001B[1;32m    236\u001B[0m }\n\u001B[1;32m    237\u001B[0m target \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: dim_zero_cat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_input_ids),\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: dim_zero_cat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_attention_mask),\n\u001B[1;32m    240\u001B[0m }\n\u001B[0;32m--> 241\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbert_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m    \u001B[49m\u001B[43mall_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mall_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_tokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_tokenizer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_forward_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_forward_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m    \u001B[49m\u001B[43midf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43midf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_device\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_threads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_threads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlang\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrescale_with_baseline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrescale_with_baseline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbaseline_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbaseline_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbaseline_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbaseline_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torchmetrics/functional/text/bert.py:422\u001B[0m, in \u001B[0;36mbert_score\u001B[0;34m(preds, target, model_name_or_path, num_layers, all_layers, model, user_tokenizer, user_forward_fn, verbose, idf, device, max_length, batch_size, num_threads, return_hash, lang, rescale_with_baseline, baseline_path, baseline_url)\u001B[0m\n\u001B[1;32m    415\u001B[0m target_embeddings, target_idf_scale \u001B[38;5;241m=\u001B[39m _get_embeddings_and_idf_scale(\n\u001B[1;32m    416\u001B[0m     target_loader, target_dataset\u001B[38;5;241m.\u001B[39mmax_length, model, device, num_layers, all_layers, idf, verbose, user_forward_fn\n\u001B[1;32m    417\u001B[0m )\n\u001B[1;32m    418\u001B[0m preds_embeddings, preds_idf_scale \u001B[38;5;241m=\u001B[39m _get_embeddings_and_idf_scale(\n\u001B[1;32m    419\u001B[0m     preds_loader, preds_dataset\u001B[38;5;241m.\u001B[39mmax_length, model, device, num_layers, all_layers, idf, verbose, user_forward_fn\n\u001B[1;32m    420\u001B[0m )\n\u001B[0;32m--> 422\u001B[0m precision, recall, f1_score \u001B[38;5;241m=\u001B[39m \u001B[43m_get_precision_recall_f1\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreds_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreds_idf_scale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_idf_scale\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;66;03m# Sort predictions\u001B[39;00m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(precision\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:  \u001B[38;5;66;03m# i.e. when all_layers = False\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torchmetrics/functional/text/bert.py:159\u001B[0m, in \u001B[0;36m_get_precision_recall_f1\u001B[0;34m(preds_embeddings, target_embeddings, preds_idf_scale, target_idf_scale)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calculate precision, recall and F1 score over candidate and reference sentences.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m \n\u001B[1;32m    148\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    156\u001B[0m \n\u001B[1;32m    157\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;66;03m# Dimensions: b = batch_size, l = num_layers, p = predictions_seq_len, r = references_seq_len, d = bert_dim\u001B[39;00m\n\u001B[0;32m--> 159\u001B[0m cos_sim \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mblpd, blrd -> blpr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreds_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_embeddings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m# Final metrics shape = (batch_size * num_layers | batch_size)\u001B[39;00m\n\u001B[1;32m    161\u001B[0m precision \u001B[38;5;241m=\u001B[39m _get_scaled_precision_or_recall(cos_sim, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m\"\u001B[39m, preds_idf_scale)\n",
      "File \u001B[0;32m~/miniconda3/envs/DeepLearning_Project/lib/python3.10/site-packages/torch/functional.py:377\u001B[0m, in \u001B[0;36meinsum\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m einsum(equation, \u001B[38;5;241m*\u001B[39m_operands)\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(operands) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_einsum\u001B[38;5;241m.\u001B[39menabled:\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001B[39;00m\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;66;03m# or the user has disabled using opt_einsum\u001B[39;00m\n\u001B[0;32m--> 377\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mequation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperands\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    379\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m opt_einsum\u001B[38;5;241m.\u001B[39mis_available():\n",
      "\u001B[0;31mRuntimeError\u001B[0m: einsum(): subscript b has size 84 for operand 1 which does not broadcast with previously seen size 27"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "bert = BERTScore()\n",
    "if not predicted_text:\n",
    "    bert_score = \"Empty prediction, no score\"\n",
    "else:\n",
    "    bert_score = bert(predicted_text, ground_truth_text)\n",
    "print(bert_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:06:33.044177Z",
     "start_time": "2023-12-19T16:56:11.313266Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "____________________________________________________________"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUiV0wpclv_l"
   },
   "outputs": [],
   "source": [
    "# End of notebook"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
